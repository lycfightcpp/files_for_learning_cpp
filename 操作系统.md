# 1 基本概念

**操作系统(Operating System，0S)**:是管理计算机硬件与软件资源的系统软件，同时也是计算机系统的内核与基石。操作系统需要处理管理与配置内存、决定系统资源供需的优先次序、控制输入与输出设备、操作网络与管理文件系统等基本事务。操作系统也提供一个让用户与系统交互的操作界面。

**shell**:它是一个程序，可从键盘获取命令并将其提供给操作系统以执行。在过去，它是类似Unix的系统上唯一可用的用户界面。如今，除了命令行界面(CLI)外，我们还具有图形用户界面。

**GUI (Graphical User Interface)**:是一种用户界面，允许用户通过图形图标和音频指示符与电子设备进行交互。

**内核模式(kernel mode)**:通常也被称为超级模式(supervisor mode)，在内核模式下，正在执行的代码具有对底层硬件的完整且不受限制的访问。它可以执行任何CPU指令并引用任何内存地址。内核模式通常保留给操作系统的最低级别，最受信任的功能。内核模式下的崩溃是灾难性的;他们将停止整个计算机。超级用户模式是计算机开机时选择的自动模式。

**用户模式(user node)**:当操作系统运行用户应用程序（例如处理文本编辑器）时，系统处于用户模式。当应用程序请求操作系统的帮助或发生中断或系统调用时，就会发生从用户模式到内核模式的转换。在用户模式下，模式位设置为1。从用户模式切换到内核模式时，它从1更改为0。

**计算机架构(computer architecture)**:在计算机工程中，计算机体系结构是描述计算机系统功能，组织和实现的一组规则和方法。它主要包括指令集、内存管理、I/O和总线结构。

**SATA(Serial ATA)**∶串行ATA(Serial Advanced Technology Attachment)，它是一种电脑总线，负责主板和大容量存储设备〈如硬盘及光盘驱动器）之间的数据传输，主要用于个人电脑。

**复用(multiplexing)**:也称为共享，在操作系统中主要指示了时间和空间的管理。对资源进行复用时，不同的程序或用户轮流使用它。他们中的第一个开始使用资源，然后再使用另一个，依此类推。

**程序计数器(Program counter)**:程序计数器是一个CPU中的寄存器，用于指示计算机在其程序序列中的位置。

**程序状态字(Program Status Word)**:它是由操作系统维护的8个字节(或64位)长的数据的集合。它跟踪系统的当前状态。

**流水线(Pipeline)**:在计算世界中，管道是一组串联连接的数据处理元素，其中一个元素的输出是下一个元素的输入。流水线的元素通常以并行或按时间分割的方式执行。通常在元素之间插入一定数量的缓冲区存储。

**系统调用(system call)**:指运行在用户空间的程序向操作系统内核请求需要更高权限运行的服务。系统调用提供用户程序与操作系统之间的接口。大多数系统交互式操作需求在内核态运行。如设备IO操作或者进程间通信。

**高速缓存行(cache lines)**:其实就是把高速缓存分割成了固定大小的块，其大小是以突发读或者突发写周期的大小为基础的。

**缓存命中(cache hit)**:当应用程序或软件请求数据时，会首先发生缓存命中。首先，中央处理单元(CPU)在其最近的内存位置（通常是主缓存）中查找数据。如果在缓存中找到请求的数据，则将其视为缓存命中。

**L1 cache**:一级缓存是CPU芯片中内置的存储库。L1缓存也称为主缓存，是计算机中最快的内存，并且最接近处理器。

**L2 cache**:二级缓存存储库，内置在CPU芯片中，包装在同一模块中，或者建在主板上。L2高速缓存提供给L1高速缓存，后者提供给处理器。L2内存比L1内存慢。

**L3 cache**:三级缓存内置在主板上或CPU模块内的存储库。L3高速缓存为L2高速缓存提供数据，其内存通常比 L2内存慢，但比主内存快。L3高速缓存提供给L2高速缓存，后者又提供给L1高速缓存，后者又提供给处理器。

**RAM(Random Access Memory)**:随机存取存储器，也叫主存，是与CPU直接交换数据的内部存储器。它可以随时读写，而且速度很快，通常作为操作系统或其他正在运行中的程序的临时数据存储介质。RAM工作时可以随时从任何一个指定的地址写入(存入)或读出(取出)信息。它与ROM的最大区别是数据的易失性，即一旦断电所存储的数据将随之丢失。RAM在计算机和数字系统中用来暂时存储程序、数据和中间结果。

**ROM (Read 0nly Memory)**∶只读存储器是一种半导体存储器，其特性是一旦存储数据就无法改变或删除，且内容不会因为电源关闭而消失。在电子或电脑系统中，通常用以存储不需经常变更的程序或数据。

**EEPROM (Electrically Erasable PROM)**∶电可擦除可编程只读存储器，是一种可以通过电子方式多次复写的半导体存储设备。

**闪存(flash memory)**:是一种电子式可清除程序化只读存储器的形式，允许在操作中被多次擦或写的存储器。这种科技主要用于一般性数据存储，以及在电脑与其他数字产品间交换传输数据，如储存卡与U盘。

**SSD(Solid State Disks)**︰固态硬盘，是一种主要以闪存作为永久性存储器的电脑存储设备。

**虚拟地址(virtual memory)**︰虚拟内存是计算机系统内存管理的一种机制。它使得应用程序认为它拥有连续可用的内存(一个连续完整的地址空间)，而实际上，它通常是被分隔成多个物理内存碎片，还有部分暂时存储在外部磁盘存储器上，在需要时进行数据交换。与没有使用虚拟内存技术的系统相比，使用这种技术的系统使得大型程序的编写变得更容易，对真正的物理内存（例如RAM)的使用也更有效率。

**MMU (Memory Management Unit)**︰内存管理单元，有时称作分页内存管理单元。它是一种负责处理中央处理器（CPU)的内存访问请求的计算机硬件。它的功能包括虚拟地址到物理地址的转换（(即虚拟内存管理)、内存保护、中央处理器高速缓存的控制等。

**context switch**:上下文切换，又称环境切换。是一个存储和重建CPU状态的机制。要交换CPU上的进程时，必需先行存储当前进程的状态，然后再将进程状态读回CPU中。

**驱动程序(device driver)**∶设备驱动程序，简称驱动程序(driver) ，是一个允许高级别电脑软件与硬件交互的程序，这种程序创建了一个硬件与硬件，或硬件与软件沟通的接口，经由主板上的总线或其它沟通子系统与硬件形成连接的机制，这样使得硬件设备上的数据交换成为可能。

**忙等(busy waiting)**︰在软件工程中，忙碌等待也称**自旋**，是一种以进程反复检查一个条件是否为真的条件，这种机制可能为检查键盘输入或某个锁是否可用。

**中断(Interrupt)**:通常，在接收到来自外围硬件（相对于中央处理器和内存)的异步信号，或来自软件的同步信号之后，处理器将会进行相应的硬件/软件处理。发出这样的信号称为进行**中断请求**(interrupt request,IRQ)。**硬件中断**导致处理器通过一个**运行信息切换**(context switch)来保存执行状态（以程序计数器和程序状态字等寄存器信息为主)﹔**软件中断**则通常作为CPU指令集中的一个指令，以可编程的方式直接指示这种运行信息切换，并将处理导向一段中断处理代码。中断在计算机多任务处理，尤其是即时系统中尤为有用。

**中断向量(interrupt vector)**︰中断向量位于中断向量表中。**中断向量表(IVT)**是将中断处理程序列表与中断向量表中的中断请求列表相关联的数据结构。中断向量表的每个条目(称为中断向量)都是中断处理程序的地址。

**DMA (Direct Memory Access)**:直接内存访问，直接内存访问是计算机科学中的一种内存访问技术。它允许某些电脑内部的硬件子系统(电脑外设)，可以独立地直接读写系统内存，而不需中央处理器(CPU)介入处理。

**总线(Bus)**︰总线(Bus)是指计算机组件间规范化的交换数据的方式，即以一种通用的方式为各组件提供数据传送和控制逻辑。

**PCIe (Peripheral Component Interconnect Express)**:官方简称PCle，是计算机总线的一个重要分支，它沿用现有的PCI编程概念及信号标准，并且构建了更加高速的串行通信系统标准。

**DMI (Direct Media Interface)**︰直接媒体接口，是英特尔专用的总线，用于电脑主板上南桥芯片和北桥芯片之间的连接。

**USB(Universal Serial Bus)**︰是连接计算机系统与外部设备的一种串口总线标准，也是一种输入输出接口的技术规范，被广泛地应用于个人电脑和移动设备等信息通讯产品，并扩展至摄影器材、数字电视（机顶盒)、游戏机等其它相关领域。

**BIOS(Basic Input Output System)**∶是在通电引导阶段运行硬件初始化，以及为操作系统提供运行时服务的固件。它是开机时运行的第一个软件。

**硬实时系统(hard real-time system)**︰硬实时性意味着你必须绝对在每个截止日期前完成任务。很少有系统有此要求。例如核系统，一些医疗应用（例如起搏器)，大量国防应用，航空电子设备等。

**软实时系统(soft real-time system)**︰软实时系统可能会错过某些截止日期，但是如果错过太多，最终性能将下降。一个很好的例子是计算机中的声音系统。

**进程(Process)**:程序本身只是指令、数据及其组织形式的描述，进程才是程序(那些指令和数据)的真正运行实例。若进程有可能与同一个程序相关系，且每个进程皆可以同步（循序）或异步的方式独立运行。

**地址空间(address space)**:地址空间是内存中可供程序或进程使用的有效地址范围。也就是说，它是程序或进程可以访问的内存。存储器可以是物理的也可以是虚拟的，用于执行指令和存储数据。

**进程表(process table)**︰进程表是操作系统维护的数据结构，该表中的每个条目(通常称为上下文块）均包含有关进程的信息，例如进程名称和状态，优先级，寄存器以及它可能正在等待的信号灯。

**inode**:索引节点的缩写，索引节点是UNIX系统中包含的信息，其中包含有关每个文件的详细言息，例如节点，所有者，文件，文件位置等。

**虚拟机(Virtual Machines)**:在计算机科学中的体系结构里，是指一种特殊的软件，可以在计算机平台和终端用户之间创建一种环境，而终端用户则是基于虚拟机这个软件所创建的环境来操作其它软件。

**中断**: 指在计算机执行期间，系统内发生任何非寻常的或非预期的急需处理事件，使得CPU暂时中断当前正在执行的程序而转去执行相应的事件处理程序，待处理完毕后又返回原来被中断处继续执行或调度新的进程执行的过程

**轮询**: 定时对各种设备轮流询问一遍有无处理要求

**中断向量表(interrupt vector table)**:用来形成相应的中断服务程序的入口地址或存放中断服务程序的首地址称为中断向量。中断向量表是中断向量的集合，中断向量是中断处理程序的地址。

**缓冲区(buffering)**:缓冲区是内存的临时存储区域，它的出现是为了加快内存的访问速度而设计的。对于经常访问的数据和指令来说，CPU应该访问的是缓冲区而非内存。

**可重入(reentrant)**:如果一段程序或者代码在任意时刻被中断后由操作系统调用其他程序或者代码，这段代码调用子程序并能够正确运行，这种现象就称为可重入。也就是说当该子程序正在运行时，执行线程可以再次进入并执行它，仍然获得符合设计时预期的结果。

**多重缓冲区(double buffering)**:它指的是使用多个缓冲区来保存数据块，每个缓冲区都保留数据块的一部分，读取的时候通过读取多个缓冲区的数据进而拼凑成一个完整的数据。

**环形缓冲区(circular buffer)**:它指的是首尾相连的缓冲区，常用来实现数据缓冲流。

**守护进程(Daemon)**:在计算机中，守护程序是作为后台进程运行的计算机程序，而不是在交互式用户的直接控制下运行的程序。

**逻辑块寻址(logical block addressing，LBA)**︰逻辑块寻址是一种通用方案，用于指定存储在计算机存储设备上的数据块的位置。

**位图(bitmap)**︰在计算机中，位图是从某个域(例如，整数范围)到位的映射。也称为位数组或位图索引。

**死锁(deadlock)**:死锁常用于并发情况下，死锁是一种状态，死锁中的每个成员都在等待另一个成员（包括其自身)采取行动。

**活锁(Livelock)**︰活锁类似于死锁，不同之处在于，活锁中仅涉及进程的状态彼此之间不断变化，没有进展。举一个现实世界的例子，当两个人在狭窄的走廊里相遇时，就会发生活锁，每个人都试图通过移动到一边让对方通过而礼貌，但最终却没有任何进展就左右摇摆，因为他们总是同时移动相同的方式。

**饥饿(starvation)**:在死锁或者活锁的状态中，在任何时刻都可能请求资源，虽然一些调度策略能够决定一些进程在某一时刻获得资源，但是有一些进程永远无法获得资源。永远无法获得资源的进程很容易产生饥饿。

**解释一下什么是操作系统**
操作系统是运行在计算机上最重要的一种软件，它管理计算机的资源和进程以及所有的硬件和软件。它为计算机硬件和软件提供了一种中间层。通常情况下，计算机上会运行着许多应用程序，它们都需要对内存和CPU进行交互，操作系统的目的就是为了保证这些访问和交互能够准确无误的进行。

**操作系统的组成**
>+ 1、驱动程序是最底层的、直接控制和监视各类硬件的部分，它们的职责是隐藏硬件的具体细节，并向其他部分提供一个抽象的、通用的接口。
>+ 2、内核是操作系统之最内核部分，通常运行在最高特权级，负责提供基础性、结构性的功能。
>+ 3、支承库是一系列特殊的程序库，它们职责在于把系统所提供的基本服务包装成应用程序所能够使用的编程接口（API），是最靠近应用程序的部分。例如，GNU C运行期库就属于此类，它把各种操作系统的内部编程接口包装成ANSI C和POSIX编程接口的形式。
>+ 4、外围是指操作系统中除以上三类以外的所有其他部分，通常是用于提供特定高级服务的部件。例如，在微内核结构中，大部分系统服务，以及UNIX/Linux中各种守护进程都通常被划归此列。

**操作系统的主要目的**
操作系统是一种软件，它的主要目的有三种:
>+ (1)管理计算机资源，这些资源包括CPU、内存、磁盘驱动器、打印机等。
>+ (2)提供一种图形界面，就像我们前面描述的那样，它提供了用户和计算机之间的桥梁。
>+ (3)为其他软件提供服务，操作系统与软件进行交互，以便为其分配运行所需的任何必要资源。

**什么是实时系统**
实时操作系统对时间做出了严格的要求，实时操作系统分为两种：硬实时和软实时
>+ 硬实时操作系统规定某个动作必须在规定的时刻内完成或发生，比如汽车生产车间，焊接机器必须在某一时刻内完成焊接，焊接的太早或者太晚都会对汽车造成永久性伤害。
>+ 软实时操作系统虽然不希望偶尔违反最终的时限要求，但是仍然可以接受。并且不会引起任何永久性伤害。比如数字音频、多媒体、手机都是属于软实时操作系统。你可以简单理解硬实时和软实时的两个指标：是否在时刻内必须完成以及是否造成严重损害。

**大内核和微内核有什么区别？**
>+ **大内核**就是将操作系统的全部功能都放进内核里面，包括调度、文件系统、网络、设备驱动器、存储管理等等，组成一个紧密连接整体。大内核的优点就是效率高，但是很难定位bug，拓展性比较差，每次需要增加新的功能，都要将新的代码和原来的内核代码重新编译。
>+ **微内核**与单体内核不同，微内核只是将操作中最核心的功能加入内核，包括IPC、地址空间分配和基本的调度，这些东西都在内核态运行，其他功能作为模块被内核调用，并且是在用户空间运行。微内核比较好维护和拓展，但是效率可能不高，因为需要频繁地在内核态和用户态之间切换。

# 2 进程与线程

**竞态条件**
竞态条件:即两个或多个线程同时对一共享数据进行修改，从而影响程序运行的正确性时，这种就被称为竞态条件(race condition)。

**影响调度程序的指标是什么**
会有下面几个因素决定调度程序的好坏
>+ **CPU使用率**。CPU 正在执行任务(即不处于空闲状态)的时间百分比。
>+ **等待时间**。这是进程轮流执行的时间，也就是进程切换的时间。
>+ **吞吐量**。单位时间内完成进程的数量。
>+ **响应时间**。这是从提交流程到获得有用输出所经过的时间。
>+ **周转时间**。从提交流程到完成流程所经过的时间。

**什么是僵尸进程**
僵尸进程是已完成且处于终止状态，但在进程表中却仍然存在的进程。僵尸进程通常发生在父子关系的进程中，由于父进程仍需要读取其子进程的退出状态所造成的。

**线程和进程的区别和联系**

区别：
>+ 1.地址空间。进程间地址空间相互独立，同一进程的各线程间共享。某进程内的线程在其它进程不可见。
>+ 2.通信方面。线程间通信可以通过共享进程中的数据实现，而进程间通信通过IPC机制,管道，Socket等方式。
>+ 3.资源。进程是资源分配的基本单位，而线程基本上不拥有资源，多个线程共享进程的资源。
>+ 4.系统开销。进程间切换代价较大，线程间切换代价较小

联系：
>+ 1.一个进程至少包含一个线程；
>+ 2.进程和线程都可以并发执行；
>+ 3.进程在执行过程中拥有独立的内存单元，其中的所有线程共享进程的内存。

**线程同步的方式有哪些？**

**临界区**、**互斥锁**、**条件变量**、**读写锁**、**自旋锁**、**信号量**

**临界区**

通过对多线程的串行化来访问公共资源或一段代码，速度快，适合控制数据访问。在任意时刻只允许一个线程对共享资源进行访问，如果有多个线程试图访问公共资源，那么在有一个线程进入后，其他试图访问公共资源的线程将被挂起，并一直等到进入临界区的线程离开，临界区在被释放后，其他线程才可以抢占。它并不是核心对象，不是属于操作系统维护的，而是属于进程维护的。

在使用临界区时，一般不允许其运行时间过长，只要进入临界区的线程还没有离开，其他所有试图进入此临界区的线程都会被挂起而进入到等待状态，并会在一定程度上影响。程序的运行性能。尤其需要注意的是不要将等待用户输入或是其他一些外界干预的操作包含到临界区。如果进入了临界区却一直没有释放，同样也会引起其他线程的长时间等待。虽然临界区同步速度很快，但却只能用来同步本进程内的线程，而不可用来同步多个进程中的线程。

**互斥量**

互斥对象和临界区很像，采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以能保证公共资源不会同时被多个线程同时访问。当前拥有互斥对象的线程处理完任务后必须将线程交出，以便其他线程访问该资源。

使用互斥不仅仅能够在同一应用程序不同线程中实现资源的安全共享，而且可以在不同应用程序的线程之间实现对资源的安全共享。 互斥量可以跨越进程使用。所以创建互斥量需要的资源更多，所以如果只为了在进程内部是用的话使用临界区会带来速度上的优势并能够减少资源占用量。

```cpp
#include <pthread.h>

/* 静态初始化 */
pthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER;

/* 动态初始化 */
int pthread_mutext_init(pthread_mutex_t *restrict mutex,
                        const pthread_mutexattr_t *restrict attr
                        );

/* 销毁互斥量 */
int pthread_mutex_destroy(pthread_mutex_t *mutex);

/* 加锁 */
int pthread_mutex_lock(pthread_mutex_t *mutex);
int pthread_mutex_trylock(pthread_mutex_t *mutex);

/* 解锁 */
int pthread_mutex_unlock(pthread_mutex_t *mutex);
```
互斥锁的特点:
>+ 1. 原子性：把一个互斥量锁定为一个原子操作，这意味着操作系统（或pthread函数库）保证了如果一个线程锁定了一个互斥量，没有其他线程在同一时间可以成功锁定这个互斥量；
>+ 2. 唯一性：如果一个线程锁定了一个互斥量，在它解除锁定之前，没有其他线程可以锁定这个互斥量；
>+ 3. 非繁忙等待：如果一个线程已经锁定了一个互斥量，第二个线程又试图去锁定这个互斥量，则第二个线程将被挂起（不占用任何cpu资源），直到第一个线程解除对这个互斥量的锁定为止，第二个线程则被唤醒并继续执行，同时锁定这个互斥量。

**条件变量**

与互斥锁不同，条件变量是用来等待而不是用来上锁的。条件变量用来自动阻塞一个线程，直 到某特殊情况发生为止。通常条件变量和互斥锁同时使用。

条件的检测是在互斥锁的保护下进行的。线程在改变条件状态之前必须首先锁住互斥量。如果一个条件为假，一个线程自动阻塞，并释放等待状态改变的互斥锁。如果另一个线程改变了条件，它发信号给关联的条件变量，唤醒一个或多个等待它的线程，重新获得互斥锁，重新评价条件。如果两进程共享可读写的内存，条件变量 可以被用来实现这两进程间的线程同步。

条件变量使我们可以睡眠等待某种条件出现。条件变量是利用线程间共享的全局变量进行同步 的一种机制，主要包括两个动作：一个线程等待"条件变量的条件成立"而挂起；另一个线程使 “条件成立”（给出条件成立信号）。

条件变量的操作流程如下：
>+ 1. 初始化：init()或者pthread_cond_tcond=PTHREAD_COND_INITIALIER；属性置为NULL；
>+ 2. 等待条件成立：pthread_wait，pthread_timewait.wait()释放锁,并阻塞等待条件变量为真 timewait()设置等待时间,仍未signal,返回ETIMEOUT(加锁保证只有一个线程wait)；
>+ 3. 激活条件变量：pthread_cond_signal,pthread_cond_broadcast(激活所有等待线程)
>+ 4. 清除条件变量：destroy;无线程等待,否则返回EBUSY清除条件变量:destroy;无线程等待,否则返回EBUSY

```cpp
#include <pthread.h>
// 初始化条件变量
int pthread_cond_init(pthread_cond_t *cond,
					  pthread_condattr_t *cond_attr);
// 阻塞等待
int pthread_cond_wait(pthread_cond_t *cond,pthread_mutex_t *mutex);
// 超时等待
int pthread_cond_timewait(pthread_cond_t *cond,
                          pthread_mutex *mutex,
						  const timespec *abstime);
// 解除所有线程的阻塞
int pthread_cond_destroy(pthread_cond_t *cond);
// 至少唤醒一个等待该条件的线程
int pthread_cond_signal(pthread_cond_t *cond);
// 唤醒等待该条件的所有线程
int pthread_cond_broadcast(pthread_cond_t *cond);
```

**读写锁**

读写锁与互斥量类似，不过读写锁允许更改的并行性，也叫共享互斥锁。互斥量要么是锁住状态，要么就是不加锁状态，而且一次只有一个线程可以对其加锁。读写锁可以有3种状态：读模式下加锁状态、写模式加锁状态、不加锁状态。

一次只有一个线程可以占有写模式的读写锁，但是多个线程可以同时占有读模式的读写锁（允许多个线程读但只允许一个线程写）。如果有其它线程读数据，则允许其它线程执行读操作，但不允许写操作；如果有其它线程写数据，则其它线程都不允许读、写操作。

如果某线程申请了读锁，其它线程可以再申请读锁，但不能申请写锁；如果某线程申请了写锁，其它线程不能申请读锁，也不能申请写锁。读写锁适合于对数据结构的读次数比写次数多得多的情况。

```cpp
#include <pthread.h>
// 初始化读写锁
int pthread_rwlock_init(pthread_rwlock_t *rwlock, 
						const pthread_rwlockattr_t *attr); 
// 申请读锁
int pthread_rwlock_rdlock(pthread_rwlock_t *rwlock ); 
// 申请写锁
int pthread_rwlock_wrlock(pthread_rwlock_t *rwlock ); 
// 尝试以非阻塞的方式来在读写锁上获取写锁，
// 如果有任何的读者或写者持有该锁，则立即失败返回。
int pthread_rwlock_trywrlock(pthread_rwlock_t *rwlock); 
// 解锁
int pthread_rwlock_unlock (pthread_rwlock_t *rwlock); 
// 销毁读写锁
int pthread_rwlock_destroy(pthread_rwlock_t *rwlock);
```

**自旋锁**

自旋锁与互斥量功能一样，唯一一点不同的就是互斥量阻塞后休眠让出cpu，而自旋锁阻塞后不会让出cpu，会一直忙等待，直到得到锁。

自旋锁在用户态使用的比较少，在内核使用的比较多！自旋锁的使用场景：锁的持有时间比较短，或者说小于2次上下文切换的时间。

自旋锁在用户态的函数接口和互斥量一样，把pthread_mutex_xxx()中mutex换成spin，如：pthread_spin_init()。

**信号量**

信号量广泛用于进程或线程间的同步和互斥，信号量本质上是一个非负的整数计数器，它被用来控制对公共资源的访问。

编程时可根据操作信号量值的结果判断是否对公共资源具有访问的权限，当信号量值大于 0 时，则可以访问，否则将阻塞。PV 原语是对信号量的操作，一次 P 操作使信号量减１，一次 V 操作使信号量加１。

P操作申请资源：
>+ （1）S减1；
>+ （2）若S减1后仍大于等于零，则进程继续执行；
>+ （3）若S减1后小于零，则该进程被阻塞后进入与该信号相对应的队列中，然后转入进程调度。

V操作释放资源：
>+ （1）S加1；
>+ （2）若相加结果大于零，则进程继续执行；
>+ （3）若相加结果小于等于零，则从该信号的等待队列中唤醒一个等待进程，然后再返回原进程继续执行或转入进程调度。

```cpp
#include <semaphore.h>
// 初始化信号量
int sem_init(sem_t *sem, int pshared, unsigned int value);
// 信号量 P 操作（减 1）
int sem_wait(sem_t *sem);
// 以非阻塞的方式来对信号量进行减 1 操作
int sem_trywait(sem_t *sem);
// 信号量 V 操作（加 1）
int sem_post(sem_t *sem);
// 获取信号量的值
int sem_getvalue(sem_t *sem, int *sval);
// 销毁信号量
int sem_destroy(sem_t *sem);
```

**3.进程的通信方式有哪些？**

**管道**、**信号量**、**消息队列**、**信号**、**共享内存**、**套接字**
>+ **管道（pipe）**：管道是一种半双工的通信方式，数据只能单向流动，而且只能在具有血缘关系的进程间使用。进程的血缘关系通常指父子进程关系。管道分为pipe（无名管道）和fifo（命名管道）两种，有名管道也是半双工的通信方式，但是它允许无亲缘关系进程间通信。
>+ **信号量（semophore）**：信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它通常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。
>+ **消息队列（message queue）**：消息队列是由消息组成的链表，存放在内核中 并由消息队列标识符标识。消息队列克服了信号传递信息少，管道只能承载无格式字节流以及缓冲区大小受限等缺点。消息队列与管道通信相比，其优势是对每个消息指定特定的消息类型，接收的时候不需要按照队列次序，而是可以根据自定义条件接收特定类型的消息。
>+ **信号（signal）**：信号是一种比较复杂的通信方式，用于通知接收进程某一事件已经发生。
>+ **共享内存（shared memory）**：共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问，共享内存是最快的IPC方式，它是针对其他进程间的通信方式运行效率低而专门设计的。它往往与其他通信机制，如信号量配合使用，来实现进程间的同步和通信。
>+ **套接字（socket）**：socket，即套接字是一种通信机制，凭借这种机制，客户/服务器（即要进行通信的进程）系统的开发工作既可以在本地单机上进行，也可以跨网络进行。也就是说它可以让不在同一台计算机但通过网络连接计算机上的进程进行通信。也因为这样，套接字明确地将客户端和服务器区分开来。

**进程的三种状态及转换**

进程在运行中不断地改变其运行状态。通常，一个运行进程必须具有以下三种基本状态。
>+ 就绪(Ready)状态。当进程已分配到除CPU以外的所有必要的资源，只要获得处理机便可立即执行，这时的进程状态称为就绪状态。
>+ 执行（Running）状态。当进程已获得处理机，其程序正在处理机上执行，此时的进程状态称为执行状态。
>+ 阻塞(Blocked)状态。正在执行的进程，由于等待某个事件发生而无法执行时，便放弃处理机而处于阻塞状态。引起进程阻塞的事件可有多种，例如，等待I/O完成、申请缓冲区不能满足、等待信件(信号)等。

一个进程在运行期间，不断地从一种状态转换到另一种状态，它可以多次处于就绪状态和执行状态，也可以多次处于阻塞状态。
>+ (1) 就绪→执行。处于就绪状态的进程，当进程调度程序为之分配了处理机后，该进程便由就绪状态转变成执行状态。
>+ (2) 执行→就绪。处于执行状态的进程在其执行过程中，因分配给它的一个时间片已用完而不得不让出处理机，于是进程从执行状态转变成就绪状态。
>+ (3) 执行→阻塞。正在执行的进程因等待某种事件发生而无法继续执行时，便从执行状态变成阻塞状态。
>+ (4) 阻塞→就绪。处于阻塞状态的进程，若其等待的事件已经发生，于是进程由阻塞状态转变为就绪状态。

**进程表**：每个进程占用一个进程表项。该表项包括程序计数器、堆栈指针、内存分配状况、所打开文件的状态、账号和调度信息，以及其他在进程由运行态转换到就绪态或阻塞态时必须保存的信息，从而保证该进程随后能够再次启动。

**线程有几种状态？**
>+ 1. **新建(NEW)**：新创建了一个线程对象。
>+ 2. **可运行(RUNNABLE)**：线程对象创建后，其他线程(比如main线程）调用了该对象的start()方法。该状态的线程位于可运行线程池中，等待被线程调度选中，获取cpu 的使用权 。
>+ 3. **运行(RUNNING)**：可运行状态(runnable)的线程获得了cpu 时间片（timeslice） ，执行程序代码。
>+ 4. **阻塞(BLOCKED)**：阻塞状态是指线程因为某种原因放弃了cpu 使用权，也即让出了cpu timeslice，暂时停止运行。直到线程进入可运行(runnable)状态，才有机会再次获得cpu timeslice 转到运行(running)状态。阻塞的情况分三种： 
>>+ (一). **等待阻塞**：运行(running)的线程执行o.wait()方法，JVM会把该线程放入等待队列(waitting queue)中。
>>+ (二). **同步阻塞**：运行(running)的线程在获取对象的同步锁时，若该同步锁被别的线程占用，则JVM会把该线程放入锁池(lock pool)中。
>>+ (三). **其他阻塞**：运行(running)的线程执行Thread.sleep(long ms)或t.join()方法，或者发出了I/O请求时，JVM会把该线程置为阻塞状态。当sleep()状态超时、join()等待线程终止或者超时、或者I/O处理完毕时，线程重新转入可运行(runnable)状态。
>+ 5. **死亡(DEAD)**：线程run()、main() 方法执行结束，或者因异常退出了run()方法，则该线程结束生命周期。死亡的线程不可再次复生。

在给定的时间点上，一个线程只能处于一种状态。


**5.操作系统中进程调度策略有哪几种？**

基本的操作系统进程调度算法包括**先来先服务（first come first serve）**，**短作业优先法（shortest job first）**，**时间片轮转（round robin）**，**多级反馈轮转法（round robin with multiple feedback）**，**优先级法（静态优先级法/动态优先级法）**，**最高响应比优先法（highest response_ratio next）**。

**先来先服务(FCFS)**，是一种最简单的调度算法，该算法既可用于作业调度，也可用于进程调度。当在作业调度中采用该算法时，每次调度都是从后备作业队列中选择一个或多个最先进入该队列的作业，将它们调入内存，为它们分配资源、创建进程，然后放入就绪队列。在进程调度中采用FCFS算法时，则每次调度是从就绪队列中选择一个最先进入该队列的进程，为之分配处理机，使之投入运行。该进程一直运行到完成或发生某事件而阻塞后才放弃处理机。

**短作业(进程)优先调度算法SJ(P)F**，是指对短作业或短进程优先调度的算法。它们可以分别用于作业调度和进程调度。短作业优先(SJF)的调度算法是从后备队列中选择一个或若干个估计运行时间最短的作业，将它们调入内存运行。而短进程优先(SPF)调度算法则是从就绪队列中选出一个估计运行时间最短的进程，将处理机分配给它，使它立即执行并一直执行到完成，或发生某事件而被阻塞放弃处理机时再重新调度。

**时间片轮转（round robin）**，这是一种基于时钟的抢占策略，以一个周期性间隔产生时钟中断，当中断发生时，当前正在运行的进程被置于就绪队列中，然后基于FCFS策略选择下一个就绪作业的运行。这种技术也称时间片，因为每个进程在被抢占前都给定一片时间。

**多级反馈轮转法（round robin with multiple feedback）**，不必事先知道各种进程所需要执行的时间，它是目前被公认的一种较好的进程调度算法。 其实施过程如下：
>+ 1) 设置多个就绪队列，并为各个队列赋予不同的优先级。在优先权越高的队列中， 为每个进程所规定的执行时间片就越小。
>+ 2) 当一个新进程进入内存后，首先放入第一队列的末尾，按FCFS原则排队等候调度。 如果他能在一个时间片中完成，便可撤离；如果未完成，就转入第二队列的末尾，在同样等待调度…… 如此下去，当一个长作业（进程）从第一队列依次将到第n队列（最后队列）后，便按第n队列时间片轮转运行。
>+ 3) 仅当第一队列空闲时，调度程序才调度第二队列中的进程运行；仅当第1到第（i-1）队列空时， 才会调度第i队列中的进程运行，并执行相应的时间片轮转。
>+ 4) 如果处理机正在处理第i队列中某进程，又有新进程进入优先权较高的队列， 则此新队列抢占正在运行的处理机，并把正在运行的进程放在第i队列的队尾。

**优先级法（静态优先级法/动态优先级法）**,系统将从后备队列中选择若干个优先权最高的作业装入内存。当用于进程调度时，该算法是把处理机分配给就绪队列中优先权最高的进程，这时，又可进一步把该算法分成如下两种。
>+ 非抢占式优先权算法。在这种方式下，系统一旦把处理机分配给就绪队列中优先权最高的进程后，该进程便一直执行下去，直至完成；或因发生某事件使该进程放弃处理机时，系统方可再将处理机重新分配给另一优先权最高的进程。
>+ 抢占式优先权调度算法。在这种方式下，系统同样是把处理机分配给优先权最高的进程，使之执行。但在其执行期间，只要又出现了另一个其优先权更高的进程，进程调度程序就立即停止当前进程(原优先权最高的进程)的执行，重新将处理机分配给新到的优先权最高的进程。

**最高响应比优先法（HRRN，Highest Response Ratio Next）**,是对FCFS方式和SJF方式的一种综合平衡。FCFS方式只考虑每个作业的等待时间而未考虑执行时间的长短，而SJF方式只考虑执行时间而未考虑等待时间的长短。因此，这两种调度算法在某些极端情况下会带来某些不便。HRN调度策略同时考虑每个作业的等待时间长短和估计需要的执行时间长短，从中选出响应比最高的作业投入执行。这样，即使是长作业，随着它等待时间的增加，W / T也就随着增加，也就有机会获得调度执行。这种算法是介于FCFS和SJF之间的一种折中算法。

# 3 内存管理

**大端小端**：**大端**：低地址存放在高存储器地址，高字节存放在低存储器地址；**小端**：高字节存放在高存储器地址，低地址存放在低存储器地址。取地址的时候都是取首地址的，读取的时候也是从首地址开始读的。

**局部性原理**
>+ (1). 时间上的局部性：最近被访问的页在不久的将来还会被访问；
>+ (2). 空间上的局部性：内存中被访问的页周围的页也很可能被访问。

**虚拟内存**：虚拟内存是计算机系统内存管理的一种技术。它使得应用程序认为它拥有连续的可用的内存（一个连续完整的地址空间），而实际上，它通常是被分隔成多个物理内存碎片，还有部分暂时存储在外部磁盘存储器上，在需要时进行数据交换。目前，大多数操作系统都使用了虚拟内存，如Windows家族的“虚拟内存”；Linux的“交换空间”等。

**分页**：分页（英语：Paging），是一种操作系统里存储器管理的一种技术，可以使电脑的主存可以使用存储在辅助存储器中的数据。操作系统会将辅助存储器（通常是磁盘）中的数据分区成固定大小的区块，称为“页”（pages）。当不需要时，将分页由主存（通常是内存）移到辅助存储器；当需要时，再将数据取回，加载主存中。相对于分段，分页允许存储器存储于不连续的区块以维持文件系统的整齐。分页是磁盘和内存间传输数据块的最小单位。

**分段**：分段机制就是把虚拟地址空间中的虚拟内存组织成一些长度可变的称为段的内存块单元。

**分页和分段有什么区别（内存管理）？**

**段式**存储管理是一种符合用户视角的内存分配管理方案。在段式存储管理中，将程序的地址空间划分为若干段（segment），如代码段，数据段，堆栈段；这样每个进程有一个二维地址空间，相互独立，互不干扰。段式管理的优点是：没有内碎片（因为段大小可变，改变段大小来消除内碎片）。但段换入换出时，会产生外碎片（比如4k的段换5k的段，会产生1k的外碎片）

**页式**存储管理方案是一种用户视角内存与物理内存相分离的内存分配管理方案。在页式存储管理中，将程序的逻辑地址划分为固定大小的页（page），而物理内存划分为同样大小的帧，程序加载时，可以将任意一页放入内存中任意一个帧，这些帧不必连续，从而实现了离散分离。页式存储管理的优点是：没有外碎片（因为页的大小固定），但会产生内碎片（一个页可能填充不满）。

两者的不同点：
>+ **目的不同**：分页是由于系统管理的需要而不是用户的需要，它是信息的物理单位；分段的目的是为了能更好地满足用户的需要，它是信息的逻辑单位，它含有一组其意义相对完整的信息；
>+ **大小不同**：页的大小固定且由系统决定，而段的长度却不固定，由其所完成的功能决定；
>+ **地址空间不同**： 段向用户提供二维地址空间；页向用户提供的是一维地址空间；
信息共享：段是信息的逻辑单位，便于存储保护和信息的共享，页的保护和共享受到限制；
>+ **内存碎片**：页式存储管理的优点是没有外碎片（因为页的大小固定），但会产生内碎片（一个页可能填充不满）；而段式管理的优点是没有内碎片（因为段大小可变，改变段大小来消除内碎片）。但段换入换出时，会产生外碎片（比如4k的段换5k的段，会产生1k的外碎片）。

**缓冲区溢出**：向缓冲区内填充数据时超过了缓冲区本身的容量，而导致数据溢出到被分配空间之外的内存空间，使得溢出的数据覆盖了其他内存空间的数据。

**空闲内存管理的方式**：在动态分配内存时，操作系统必须对其进行管理。有两种方式跟踪内存使用情况：位图和空闲链表。
>+ **使用位图的存储管理**。使用位图方法时，内存可能被划分成小到几个字或大到几千字节的分配单元。每个分配单元对应于位图中的一位，0表示空闲，1表示占用（或者相反）。
>+ **使用链表的存储管理**。维护一个记录已分配内存段和空闲内存段的链表。其中链表中的一个结点或者包含一个进程，或者是两个进程间的一个空的空闲区。链表中的每一个结点都包含以下域：空闲区（H）或进程（P）的指示标志、起始地址、长度和指向下一结点的指针。

**什么是按需分页**
在操作系统中，进程是以页为单位加载到内存中的，按需分页是一种**虚拟内存**的管理方式。在使用请求分页的系统中，只有在尝试访问页面所在的磁盘并且该页面尚未在内存中时，也就发生了**缺页异常**，操作系统才会将磁盘页面复制到内存中。

**什么是虚拟内存**
**虚拟内存**是一种内存分配方案，是一项可以用来辅助内存分配的机制。我们知道，应用程序是按页装载进内存中的。但并不是所有的页都会装载到内存中，计算机中的硬件和软件会将数据从 RAM临时传输到磁盘中来弥补内存的不足。如果没有虚拟内存的话，一旦你将计算机内存填满后，无法再加载任何应用程序，只能另一个应用程序以加载新的应用程序。对于虚拟内存，计算机可以执行操作是查看内存中最近未使用过的区域，然后将其复制到硬盘上。虚拟内存通过复制技术使计算机能够运行大于内存的程序。复制是自动进行的，你无法感知到它的存在。

**页面置换算法**
>+ **最优算法**在当前页面中置换最后要访问的页面。不幸的是，没有办法来判定哪个页面是最后一个要访问的，因此实际上该算法不能使用。然而，它可以作为衡量其他算法的标准。
>+ **NRU**算法根据R位和M位的状态将页面氛围四类。从编号最小的类别中随机选择一个页面。NRU算法易于实现,但是性能不是很好。存在更好的算法。
>+ **FIFO**会跟踪页面加载进入内存中的顺序，并把页面放入一个链表中。有可能删除存在时间最长但是还在使用的页面，因此这个算法也不是一个很好的选择。
>+ **第二次机会**算法是对FIFO的一个修改，它会在删除页面之前检查这个页面是否仍在使用。如果页面正在使用，就会进行保留。这个改进大大提高了性能。
>+ **时钟**算法是第二次机会算法的另外一种实现形式，时钟算法和第二次算法的性能差不多，但是会花费更少的时间来执行算法。
>+ **LRU**算法是一个非常优秀的算法，但是没有特殊的硬件(TLB)很难实现。如果没有硬件，就不能使用LRU算法。
>+ **NFU**算法是一种近似于LRU的算法，它的性能不是非常好。
>+ **老化**算法是一种更接近LRU算法的实现，并且可以更好的实现，因此是一个很好的选择最后两种算法都使用了工作集算法。工作集算法提供了合理的性能开销，但是它的实现比较复杂。**WSClock**是另外一种变体，它不仅能够提供良好的性能，而且可以高效地实现。

**最好的算法是老化算法和WSClock算法**。他们分别是基于LRU和工作集算法。他们都具有良好的性能并且能够被有效的实现。还存在其他一些好的算法，但实际上这两个可能是最重要的。

<div align=center><img src="picture/页面置换算法.png"></div>


# 4 文件系统

**硬链接**：硬链接是通过索引节点进行的链接。在Linux中，多个文件指向同一个索引节点是允许的，像这样的链接就是硬链接。硬链接只能在同一文件系统中的文件之间进行链接，不能对目录进行创建。如果删除硬链接对应的源文件，则硬链接文件仍然存在，而且保存了原有的内容，这样可以起到防止因为误操作而错误删除文件的作用。由于硬链接是有着相同 inode 号仅文件名不同的文件，因此，删除一个硬链接文件并不影响其他有相同 inode 号的文件。

**软链接**：软链接（也叫符号链接）与硬链接不同，文件用户数据块中存放的内容是另一文件的路径名的指向。软链接就是一个普通文件，只是数据块内容有点特殊。软链接可对文件或目录创建。软链接主要应用于以下两个方面：一是方便管理，例如可以把一个复杂路径下的文件链接到一个简单路径下方便用户访问；另一方面就是解决文件系统磁盘空间不足的情况。例如某个文件文件系统空间已经用完了，但是现在必须在该文件系统下创建一个新的目录并存储大量的文件，那么可以把另一个剩余空间较多的文件系统中的目录链接到该文件系统中，这样就可以很好的解决空间不足问题。删除软链接并不影响被指向的文件，但若被指向的原文件被删除，则相关软连接就变成了死链接。

# 5 输入/输出

**中断整体流程**：
>+ 1.中断硬件处理流程。
>+ 2.软件处理流程。包括三种情况，IRQ中断，异常，系统调用。
>+ 3.从中断返回的硬件流程。（iret）

**中断处理硬件流程**：
>+ 1.cpu执行完一条指令后检查intr线查看是否发生了中断。如果发生的话跳转到第2步。
>+ 2.从总线获取中断向量。
>+ 3.到idt中找到对应的中断描述符。检查该中断是否合法。首先中断描述符中的段选择符的dpl优先级必须高于等于当前cpu特权级。其次中断描述符中的dpl优先级必须低于等于当前cpu特权级。（限制用户态程序只能经过特定的门）
>+ 4.比较中断描述符中的段选择符的dpl和当前的cpu特权级，判断是否从用户台进入了内核态。如果发生了跳转到第5步，否则第6步。
>+ 5.从tss段获取内核态的ss，esp装载当前的ss，esp寄存器。然后保存旧的ss，esp到新栈中。（这一步实际上就是用户台到内核态的切换）
>+ 6.在栈中保存eflags,cs,eip内容。
>+ 7.如果异常产生了一个硬件出错码，将它保存在栈中。
>+ 8.装载新的cs，eip寄存器（就是中断处理程序的入口，从中断描述符里可以找到）

# 6 死锁

**死锁**：死锁是指两个或两个以上的进程在执行过程中，由于竞争资源或者由于彼此通信而造成的一种阻塞的现象，若无外力作用，它们都将无法推进下去。此时称系统处于死锁状态或系统产生了死锁，这些永远在互相等待的进程称为死锁进程。

**可抢占资源(preemptable resource)**可以从拥有它的进程中抢占而不会造成其他影响，内存就是一种可抢占性资源，任何进程都能够抢先获得内存的使用权。

**不可抢占资源(nonpreemtable resource)**指的是除非引起错误或者异常，否则进程无法抢占指定资源，这种不可抢占的资源比如有光盘，在进程执行调度的过程中，其他进程是不能得到该资源的。

**产生死锁的必要条件**：
>+ **互斥条件**:每个资源都被分配给了一个进程或者资源是可用的
>+ **保持和等待条件**:已经获取资源的进程被认为能够获取新的资源
>+ **不可抢占条件**︰分配给一个进程的资源不能强制的从其他进程抢占资源，它只能由占有它的进程显示释放
>+ **循环等待**:死锁发生时，系统中一定有两个或者两个以上的进程组成一个循环，循环中的每个进程都在等待下一个进程释放的资源。

**死锁解决的方法**：死锁防止、死锁避免、死锁检测和恢复。

**死锁防止**：在程序运行之前防止发生死锁。前面说了死锁产生的条件有四个，分别是：互斥条件、占有和等待条件、不剥夺条件、循环等待条件。而死锁防止的策略就是至少破坏这四个条件其中一项。
>+ **破坏互斥条件**。使资源同时访问而非互斥使用，就没有进程会阻塞在资源上，从而不发生死锁。(只读数据文件、磁盘等软硬件资源均可采用这种办法管理；但是许多资源是独占性资源，如可写文件、键盘等只能互斥的占有；所以这种做法在许多场合是不适用的。)
>+ **破坏占有和等待条件**。采用静态分配的方式，静态分配的方式是指进程必须在执行之前就申请需要的全部资源，且直至所要的资源全部得到满足后才开始执行。(实现简单，但是严重的减低了资源利用率。因为在每个进程占有的资源中，有些资源在运行后期使用，有些资源在例外情况下才被使用，可能会造成进程占有一些几乎用不到的资源，而使其他想使用这些资源的进程等待。)
>+ **破坏不剥夺条件**。剥夺调度能够防止死锁，但是只适用于内存和处理器资源。**方法一**：占有资源的进程若要申请新资源，必须主动释放已占有资源，若需要此资源，应该向系统重新申请。**方法二**：资源分配管理程序为进程分配新资源时，若有则分配；否则将剥夺此进程已占有的全部资源，并让进程进入等待资源状态，资源充足后再唤醒它重新申请所有所需资源。
>+ **破坏循环等待条件**。给系统的所有资源编号，规定进程请求所需资源的顺序必须按照资源的编号依次进行。采用层次分配策略，将系统中所有的资源排列到不同层次中。一个进程得到某层的一个资源后，只能申请较高一层的资源；当进程释放某层的一个资源时，必须先释放所占有的较高层的资源；当进程获得某层的一个资源时，如果想申请同层的另一个资源，必须先释放此层中已占有的资源

**死锁避免**：各种死锁防止方法能够防止发生死锁，但必然会降低系统并发性，导致低效的资源利用率。
>+ 预防死锁的几种策略，会严重地损害系统性能。因此在避免死锁时，要施加较弱的限制，从而获得 较满意的系统性能。由于在避免死锁的策略中，允许进程动态地申请资源。因而，系统在进行资源分配之前预先计算资源分配的安全性。若此次分配不会导致系统进入不安全的状态，则将资源分配给进程；否则，进程等待。其中最具有代表性的避免死锁算法是银行家算法。
>+ **银行家算法**：首先需要定义状态和安全状态的概念。系统的状态是当前给进程分配的资源情况。因此，状态包含两个向量Resource（系统中每种资源的总量）和Available（未分配给进程的每种资源的总量）及两个矩阵Claim（表示进程对资源的需求）和Allocation（表示当前分配给进程的资源）。安全状态是指至少有一个资源分配序列不会导致死锁。当进程请求一组资源时，假设同意该请求，从而改变了系统的状态，然后确定其结果是否还处于安全状态。如果是，同意这个请求；如果不是，阻塞该进程知道同意该请求后系统状态仍然是安全的。

**死锁检测**：如果进程 - 资源分配图中**无环路**，此时系统没有发生死锁。如果进程 - 资源分配图中**有环路**，则可分为以下两种情况：**(1)**每种资源类中仅有一个资源，则系统发生了死锁。此时，环路是系统发生死锁的充分必要条件，环路中的进程就是死锁进程；**(2)**每种资源类中有多个资源，则环路的存在只是产生死锁的必要不充分条件，系统未必会发生死锁。
>+ 每种类型一个资源的死锁检测算法是通过检测有向图是否存在环来实现，从一个节点出发进行深度优先搜索，对访问过的节点进行标记，如果访问了已经标记的节点，就表示有向图存在环，也就是检测到死锁的发生。

**死锁恢复**:
>+ **资源剥夺法**：剥夺陷于死锁的进程所占用的资源，但并不撤销此进程，直至死锁解除。
>+ **进程回退法**：根据系统保存的检查点让所有的进程回退，直到足以解除死锁，这种措施要求系统建立保存检查点、回退及重启机制。
>+ **进程撤销法**：
>>+ 撤销陷入死锁的所有进程，解除死锁，继续运行。
>>+ 逐个撤销陷入死锁的进程，回收其资源并重新分配，直至死锁解除。
>+ **系统重启法**：结束所有进程的执行并重新启动操作系统。这种方法很简单，但先前的工作全部作废，损失很大。