# 1.网络基础知识

![](picture/osi.png)

**WAN**：Wide Area Network，广域网

**LAN**：Local Area Network，局域网

TCP/IP 协议族是一个四层协议系统，自底而上分别是**数据链路层**、**网络层**、**传输层**和**应用层**。

**数据链路层**：实现了网卡接口的网络驱动程序，以处理数据在物理媒介上的传输。数据链路层常用的两个协议是**ARP协议（Address Resolve Protocol，地址解析协议）**和**RARP协议（Reverse Address Resolve Protocol，逆地址解析协议）**。它们实现了IP地址和机器物理地址之间的相互转换。

**网络层**：实现数据包的选路和转发。网络层的任务就是选择中间节点，以确定两台主机之间的通信路径。网络层最核心的协议是**IP协议（Internet Protocol，因特网协议）**。IP协议根据数据包的目的IP地址来决定如何投递它。另一个重要的协议是**ICMP协议（Internet Control Message Protocol，因特网控制报文协议）**。它是IP协议的重要补充，主要用于检测网络连接。

**传输层**：传输层为两台主机上的应用程序提供端到端的通信。与网络层使用的逐跳通信方式不同，传输层只关心通信的起始端和目的端，而不在乎数据包的中转过程。传输层协议主要有三个：**TCP**、**UDP**和**SCTP**协议。
>+ **TCP协议(Transmission Control Protocol，传输控制协议)** 为应用层提供可靠的、面向连接的和基于流（stream）的服务。TCP协议使用超时重传、数据确认等方式来确保数据包被正确地发送至目的端，因此TCP服务是可靠的。使用TCP协议通信的双方必须先建立TCP连接，并在内核中为该连接维持一些必要的数据结构，比如连接的状态、读写缓冲区，以及诸多定时器等。当通信结束时，双方必须关闭连接以释放这些内核数据。TCP服务是基于流的。基于流的数据没有边界（长度）限制，它源源不断地从通信的一端流入另一端。发送端可以逐个字节地向数据流中写人数据，接收端也可以逐个字节地将它们读出。
>+ **UDP协议(User Datagram Protocol，用户数据报协议)** 则与TCP协议完全相反，它为应用层提供不可靠、无连接和基于数据报的服务。“不可靠”意味着UDP协议无法保证数据从发送端正确地传送到目的端。如果数据在中途丢失，或者目的端通过数据校验发现数据错误而将其丢弃，则UDP协议只是简单地通知应用程序发送失败。因此，使用UDP协议的应用程序通常要自己处理数据确认、超时重传等逻辑。UDP协议是无连接的，即通信双方不保持一个长久的联系，因此应用程序每次发送数据都要明确指定接收端的地址（IP地址等信息)。基于数据报的服务，是相对基于流的服务而言的。每个UDP数据报都有一个长度，接收端必须以该长度为最小单位将其所有内容一次性读出，否则数据将被截断。

**应用层**：应用层负责处理应用程序的逻辑。数据链路层、网络层和传输层负责处理网络通信细节，这部分必须既稳定又高效，因此它们都在内核空间中实现。应用层则在用户空间实现（也有少数服务器程序在内核中实现）。DNS（Domain Name Service，域名服务）协议提供机器域名到IP地址的转换。

![](picture/7层通信.png)

TCP/IP 通信中使用 **MAC地址**(无分层地址)、**IP 地址**(有分层地址)、**端口号**等信息作为地址标识。

<div align=center><img src="picture/协议群.png"></div>
<div align=center><img src="picture/邮件发送示意图.png"></div>
<div align=center><img src="picture/数据包处理流程.png"></div>

# 2.数据链路

数据链路是让互联计算机之间相互通信的一种协议。

数据链路层提供直连两个设备之间的通信功能。

数据链路层是OSI参考模型中的第二层，介乎于物理层和网络层之间。数据链路层在物理层提供的服务的基础上向网络层提供服务，其最基本的服务是将源自网络层来的数据可靠地传输到相邻节点的目标机网络层。

**基本功能**：
>+ **帧同步**。
>+ **差错控制**。
>+ **流量控制**。
>+ **链路管理**。

**MAC 地址**：它是一个用来确认网络设备位置的位址。MAC 地址用于在网络中唯一标示一个网卡，一台设备若有一或多个网卡，则每个网卡都需要并会有一个唯一的 MAC 地址。

# 3.IP 协议

IP 大致分为三大作用模块：IP 寻址、路由、IP 分包与组包。

**路由控制**：是指将分组数据发送到最终目标地址的功能。

**多跳路由**：是指路由器或者主机在转发 IP 数据包时只指定下一个路由器或者主机，而不是将到最终目标地址为止的所有通路全都指定下来。

**路由控制表**：为了将数据包发送给目标主机，所有主机都维护着一张路由控制表。该表记录 IP 数据在下一步应该发给哪个路由器。

**IP 面向无连接**：即在发包之前，不需要建立与对端目标地址之间的连接。上层如果遇到需要发送给 IP 的数据，该数据回立即被压缩成 IP 包发送出去。(优点：简化、提速)。

**IPv4 地址**由32位正整数来表示。

IP 地址由 "**网络标识(网络地址)**" 和 "**主机标识(主机地址)**" 两部分组成。

**全局 IP 地址**基本上要在整个互联网范围内保持唯一。但**私有地址**只需要在同一个域里保证唯一即可。

**分片机制**：导致路由器负荷加重、网络利用率下降。

**路径 MTU 发现**：路径 MTU 指从发送端主机到接收端主机之间不需要分片时最大 MTU 的大小 (即路径中存在的所有数据链路中最小的 MTU)。路径 MTU 发现从发送主机按照路径 MTU 的大小将数据包分片后进行发送。

**IPv6 地址**长度是 IPv4 的 4 倍，128 比特。

**IPv4 首部**：
>+ 版本。4 比特。表示标识 IP 地址的版本号。
>+ 首部长度。4 比特。表明 IP 首部大小。
>+ 区分服务。8 比特。表明服务质量。
>+ 总长度。16 比特。表示 IP 首部与数据部分合起来的总字节数。
>+ 标识。16 比特。用于分片重组，不同的分片标识值不同。
>+ 标志。3 比特。表示包被分片的信息。
>+ 片偏移。13 比特。用来标识被分片的每一个分段相对于原始数据的位置。
>+ 生存时间。8 比特。标明可以中转多少个路由器。
>+ 协议。8 比特。表示 IP 首部的下一个首部隶属于哪个协议。
>+ 首部校验和。16 比特。只校验数据报的首部，用来确保 IP 数据报不被破坏。
>+ 源地址。32 比特。表示发送端地址。
>+ 目标地址。32 比特。表示接收端地址。
>+ 可选项。长度可变。只在实验或诊断时使用，包含安全级别、源路径、路径记录、时间戳等信息。
>+ 填充。向字段填充 0，调整为 32 比特的整数倍。
>+ 数据。将 IP 上层协议的首部也作为数据进行处理。

**IPv6 首部**：
>+ 版本。4 比特。表示标识 IP 地址的版本号。
>+ 通信量类。8 比特。相当于 IPv4 的 TOS(Type Of Service)。
>+ 流标号。20 比特。进行流量服务控制。
>+ 有效载荷长度。表示数据部分长度。
>+ 下一个首部。8 比特。通常表示 IP 的上一层协议是 TCP 或 UDP。
>+ 跳数限制。8 比特。可通过路由器个数。
>+ 源地址。128 比特。发送端地址。
>+ 目标地址。128 比特。接收端地址。
>+ IPv6 扩展首部。任意长度。对功能进行有效扩展。

<font face="黑体" color=#556B2F size=5>DNS</font>
<font face="黑体" color=#8FBC8F size=4>(Domain Name System，域名系统)</font>

解析器为了调查 IP 地址，向域名服务器进行查询处理。接受这个查询请求的域名服务器首先会在自己的数据库进行查找。如果有该域名所对应的 IP 地址就返回。如果没有，则域名服务器再向上一层根域名服务器进行查询处理。解析器和域名服务器将最新了解到的信息暂时保存在缓存里，可以减少每次查询时的性能消耗。

<div align=center><img src="picture/DNS查询.png"></div>


<font face="黑体" color=#556B2F size=5>ARP</font>
<font face="黑体" color=#8FBC8F size=4>(Address Resolution Protocol，地址解析协议)</font>

ARP 是一种解决地址问题的协议。以目标 IP 地址为线索，用来定位下一个应该接收数据分包的网络设备对应的 MAC 地址。如果目标主机不在同一个链路上时，可以通过 ARP 查找下一跳路由器的 MAC 地址。不过 ARP 只适用于 IPv4，不能用于 IPv6。IPv6 中可以用 ICMPv6 替代 ARP 发送邻居探索消息。

**工作过程**：
主机 A 的 IP 地址为 192.168.1.1，MAC 地址为 0A-11-22-33-44-01；

主机 B 的 IP 地址为 192.168.1.2，MAC 地址为 0A-11-22-33-44-02；

当主机 A 要与主机 B 通信时，地址解析协议可以将主机 B 的 IP 地址 (192.168.1.2) 解析成主机 B 的 MAC 地址，以下为工作流程：
>+ **第 1 步**：根据主机 A 上的路由表内容，IP 确定用于访问主机 B 的转发 IP 地址是 192.168.1.2。然后 A 主机在自己的本地 ARP 缓存中检查主机 B 的匹配 MAC 地址。
>+ **第 2 步**：如果主机 A 在 ARP 缓存中没有找到映射，它将询问 192.168.1.2的硬件地址，从而将 ARP 请求帧广播到本地网络上的所有主机。源主机 A 的 IP 地址和 MAC 地址都包括在 ARP 请求中。本地网络上的每台主机都接收到 ARP 请求并且检查是否与自己的 IP 地址匹配。如果主机发现请求的 IP 地址与自己的 IP 地址不匹配，它将丢弃 ARP 请求。
>+ **第 3 步**：主机 B 确定 ARP 求中的 IP 地址与自己的 IP 地址匹配，则将主机 A 的 IP 地址和 MAC 地址映射添加到本地 ARP 缓存中。
>+ **第 4 步**：主机 B 将包含其 MAC 地址的 ARP 回复消息直接发送回主机 A。
>+ **第 5 步**：当主机 A 收到从主机 B 发来的 ARP 回复消息时，会用主机 B 的 IP 和 MAC 地址映射更新 ARP 缓存。本机缓存是有生存期的，生存期结束后，将再次重复上面的过程。主机 B 的 MAC 地址一旦确定，主机 A 就能向主机 B 发送 IP 通信了。

**RARP (Reverse Address Resolution Protocol)**。RARP 是将 ARP 反过来，从 MAC 地址定位 IP 地址的一种协议。例如将打印机服务器等小型嵌入式设备接人到网络时就经常会用得到。

**代理 ARP (Proxy ARP)**。通常 ARP 包会被路由器隔离，但是采用代理 ARP 的路由器可以将 ARP 请求转发给邻近的网段。由此，两个以上网段的节点之间可以像在同一个网段中一样进行通信。

<font face="黑体" color=#556B2F size=5>ICMP</font>
<font face="黑体" color=#8FBC8F size=4>(Internet Control Message Protocol，Internet 控制报文协议)</font>

ICMP 协议是一种面向无连接的协议，用于传输出错报告控制信息。它是一个非常重要的协议，它对于网络安全具有极其重要的意义。它属于网络层协议，主要用于在主机与路由器之间传递控制信息，包括报告错误、交换受限控制和状态信息等。当遇到 IP 数据无法访问目标、IP 路由器无法按当前的传输速率转发数据包等情况时，会自动发送 ICMP 消息。

ICMP 是 TCP/IP 模型中网络层的重要成员，与 IP 协议、ARP 协议、RARP 协议及 IGMP 协议共同构成 TCP/IP 模型中的网络层。ping 和 tracert是两个常用网络管理命令，ping 用来测试网络可达性，tracert 用来显示到达目的主机的路径。ping 和 tracert 都利用 ICMP 协议来实现网络功能，它们是把网络协议应用到日常网络管理的典型实例。

**其功能主要有**：侦测远端主机是否存在，建立及维护路由资料，重导资料传送路径 (ICMP 重定向)，资料流量控制。ICMP 在沟通之中，主要是透过不同的类别  (Type) 与代码 (Code) 让机器来识别不同的连线状况。

**工作原理**：ICMP提供一致易懂的出错报告信息。发送的出错报文返回到发送原数据的设备，因为只有发送设备才是出错报文的逻辑接受者。发送设备随后可根据ICMP报文确定发生错误的类型，并确定如何才能更好地重发失败的数据包。但是ICMP唯一的功能是报告问题而不是纠正错误，纠正错误的任务由发送方完成。

**主要的 ICMP 消息**：
>+ **ICMP 目标不可到达消息 (类型 3)**。IP 路由器无法将 IP 数据包发送给目标地址时，会给发送端主机返回一个目标不可达 (Destination Unreachable Message) 的 ICMP 消息，并在这个消息中显示不可达的具体原因。
>+ **ICMP 重定向消息 (类型 5)**。如果路由器发现发送端主机使用了次优的路径发送数据，那么它会返回一个 ICMP 重定向 (ICMP Redirect Message) 的消息给这个主机。在这个消息中包含了最合适的路由信息和源数据。这主要发生在路由器持有更好的路由信息的情况下。路由器会通过这样的 ICMP 消息给发送端主机一个更合适的发送路由。
>+ **ICMP 超时消息 (类型 11)**。TTL 为零时 IP 路由器将会发送一个 ICMP 超时的消息 (ICMP Time Exceeded Message，错误号 0) 给发送端主机，并通知该包已被丢弃。设置 IP 包生存周期的主要目的，是为了在路由控制遇到问题发生循环状况时，避免 IP 包无休止地在网络上被转发。此外，有时可以用 TTL 控制包的到达范围，例如设置一个较小的 TTL 值。
>+ **ICMP 回送消息 (类型 0、8)**。用于进行通信的主机或路由器之间，判断所发送的数据包是否已经成功到达对端的一种消息。可以向对端主机发送回送请求的消息 (ICMP Echo Request Message，类型 8)，也可以接收对端主机发回来的回送应答消息 (IMP Echo ReplMessage，类型 0)。网络上最常用的 ping 命令就是利用这个消息实现的。
>+ **ICMP 原点抑制消息 (类型 4)**。ICMP 原点抑制消息的目的是为了缓和这网络拥堵情况。当路由器向低速线路发送数据时，其发送队列的残存变为零而无法发送出去时，可以向 IP 包的源地址发送一个 ICMP 原点抑制 (ICMP Source Quench Message) 消息。收到这个消息的主机借此了解在整个线路的某一处发生了拥堵的情况，从而打开 IP 包的传输间隔。
>+ **ICMP 路由探索消息 (类型 9、10)**。主要用于发现与自己相连网络中的路由器。当一台主机发出 ICMP 路由器请求 (Router Solicitaion，类型 10) 时，路由器则返回 ICMP 路由器公告消息 (Router Advertisement，类型 9) 给主机。
>+ **ICMP 地址掩码消息 (类型 17、18)**。主要用于主机或路由器想要了解子网掩码的情况。可以向那些目标主机或路由器发送 ICMP 地址掩码请求消息 (ICMP Address Mask Request，类型 17)，然后通过接收 ICMP 地址掩码应答消息 (ICMP Address Mask Reply，类型 18) 获取子网掩码的信息。

**ICMPv6**：在 IPv6 中，从 IP 地址定位 MAC 地址的协议从 ARP 转为 ICMP 的邻居探索消息 (Neighbor Discovery)。这种邻居探索消息融合了 IPv4 的 ARP、ICMP 重定向以及 ICMP 路由器选择消息等功能于一体，甚至还提供自动设置 IP 地址的功能。
>+ **邻居探索**。邻居请求消息用于查询 IPv6 的地址与 MAC 地址的对应关系，并由邻居宣告消息得知 MAC 地址。邻居请求消息利用 IPv6 的多播地址实现传输。

<font face="黑体" color=#556B2F size=5>DHCP</font>
<font face="黑体" color=#8FBC8F size=4>(Dynamic Host Configuration Protocol，动态主机配置协议)</font>

DHCP 指的是由服务器控制一段 IP 地址范围，客户机登录服务器时就可以自动获得服务器分配的 IP 地址和子网掩码。计算机只要连接到网络，就可以进行 TCP/IP 通信，让即插即用变得可能。

DHCP 通常被应用在大型的局域网络环境中，主要作用是集中的管理、分配 IP 地址，使网络环境中的主机动态的获得 IP 地址、Gateway 地址、DNS 服务器地址等信息，并能够提升地址的使用率。

DHCP 协议采用 客户端/服务器 模型，主机地址的动态分配任务由网络主机驱动。当 DHCP 服务器接收到来自网络主机申请地址的信息时，才会向网络主机发送相关的地址配置等信息，以实现网络主机地址信息的动态配置。

**DHCP有三种机制分配IP地址**：
>+ **自动分配方式 (Automatic Allocation)**，DHCP 服务器为主机指定一个永久性的 IP 地址，一旦 DHCP 客户端第一次成功从 DHCP 服务器端租用到 IP 地址后，就可以永久性的使用该地址。
>+ **动态分配方式 (Dynamic Allocation)**，DHCP 服务器给主机指定一个具有时间限制的 IP 地址，时间到期或主机明确表示放弃该地址时，该地址可以被其他主机使用。
>+ **手工分配方式 (Manual Allocation)**，客户端的 IP 地址是由网络管理员指定的，DHCP 服务器只是将指定的IP地址告诉客户端主机。

<div align=center><img src="picture/DHCP原理.png"></div>

**DHCP 服务器**：DHCP 服务器是一种动态分配主机 IP 的协议，在局域网的管理中主要作用是为其他计算机分配动态、静态的地址，避免因自行设定 IP 地址而引起的地址冲突。

**DHCP 中继代理**：DHCPRelay (DHCPR) DHCP 中继也叫做 DHCP 中继代理。DHCP 中继代理，就是在 DHCP 服务器和客户端之间转发 DHCP 数据包。当 DHCP 客户端与服务器不在同一个子网上，就必须有 DHCP 中继代理来转发 DHCP 请求和应答消息。DHCP 中继代理的数据转发，与通常路由转发是不同的，通常的路由转发相对来说是透明传输的，设备一般不会修改 IP 包内容。而 DHCP 中继代理接收到 DHCP 消息后，重新生成一个 DHCP 消息，然后转发出去。

<font face="黑体" color=#556B2F size=5>NAT</font>
<font face="黑体" color=#8FBC8F size=4>(Network Address Translator，网络地址转换)</font>

当在专用网内部的一些主机本来已经分配到了本地 IP 地址 (即仅在本专用网内使用的专用地址)，但现在又想和因特网上的主机通信 (并不需要加密) 时，可使用 NAT 方法。这种通过使用少量的全球IP地址 (公网IP地址) 代表较多的私有 IP 地址的方式，将有助于减缓可用的 IP 地址空间的枯竭。

**功能**：
>+ **宽带分享**：这是 NAT 主机的最大功能。
>+ **安全防护**：NAT 之内的 PC 联机到 Internet 上面时，他所显示的 IP 是 NAT 主机的公共 IP，所以 Client 端的 PC 当然就具有一定程度的安全了，外界在进行 portscan (端口扫描) 的时候，就侦测不到源 Client 端的 PC 。

**实现方式**：
>+ **静态转换**是指将内部网络的私有 IP 地址转换为公有 IP 地址，IP 地址对是一对一的，是一成不变的，某个私有 IP 地址只转换为某个公有 IP 地址。借助于静态转换，可以实现外部网络对内部网络中某些特定设备 (如服务器) 的访问。
>+ **动态转换**是指将内部网络的私有 IP 地址转换为公用 IP 地址时，IP 地址是不确定的，是随机的，所有被授权访问上 Internet 的私有 IP 地址可随机转换为任何指定的合法 IP 地址。也就是说，只要指定哪些内部地址可以进行转换，以及用哪些合法地址作为外部地址时，就可以进行动态转换。动态转换可以使用多个合法外部地址集。当 ISP 提供的合法 IP 地址略少于网络内部的计算机数量时。可以采用动态转换的方式。
>+ **端口多路复用 (Port address Translation, PAT)** 是指改变外出数据包的源端口并进行端口转换，即端口地址转换 (PAT，Port Address Translation)。采用端口多路复用方式。内部网络的所有主机均可共享一个合法外部 IP 地址实现对 Internet 的访问，从而可以最大限度地节约 IP 地址资源。同时，又可隐藏网络内部的所有主机，有效避免来自 internet 的攻击。因此，目前网络中应用最多的就是端口多路复用方式。
>+ **ALG (Application Level Gateway)**，即应用程序级网关技术：传统的 NAT 技术只对 IP 层和传输层头部进行转换处理，但是一些应用层协议，在协议数据报文中包含了地址信息。为了使得这些应用也能透明地完成 NAT 转换，NAT 使用一种称作 ALG 的技术，它能对这些应用程序在通信时所包含的地址信息也进行相应的 NAT 转换。

**NAPT (Network Address Port Translation)**：即网络地址端口转换，可将多个内部地址映射为一个合法公网地址，但以不同的协议端口号与不同的内部地址相对应，也就是与之间的转换。NAPT 普遍用于接入设备中，它可以将中小型的网络隐藏在一个合法的IP地址后面。NAPT也被称为 “多对一” 的 NAT，或者叫 PAT (Port Address Translations，端口地址转换)、地址超载 (address overloading)。

**NAT 的潜在问题**：
>+ 无法从 NAT 的外部向内部服务器建立连接。
>+ 转换表的生成与转换操作都会产生一定的开销。
>+ 通信过程中一旦 NAT 遇到异常需重新启动时，所有的 TCP 连接都将被重置。
>+ 即使备置两台 NAT做容灾备份，TCP 连接还是会被断开。

**解决办法**：
>+ 改用 IPv6。
>+ NAT 穿越。

<font face="黑体" color=#556B2F size=5>IP 隧道</font>

IP隧道技术：是路由器把一种网络层协议封装到另一个协议中传送到另一个路由器的处理过程。

# 4.TCP 与 UDP

**端口号**：端口号用来识别同一台计算机中进行通信的不同应用程序。

因此，TCP/IP 或 UDP/IP 通信中通常采用 5 个信息来识别一个通信。它们是 **“源IP地址”**、**“目标IP地址”**、**“协议号”**、**“源端口号”**、**“目标端口号”**。只要其中某一项不同，则被认为是其他通信。

<font face="黑体" color=#556B2F size=5>TCP</font>
<font face="黑体" color=#8FBC8F size=4>(Transmission Control Protocol)</font>

TCP 是一种面向连接的、可靠的、基于字节流的传输层通信协议。

**特点**：
>+ 基于流的方式；
>+ 面向连接；
>+ 可靠通信方式；
>+ 在网络状况不佳的时候尽量降低系统由于重传带来的带宽开销；
>+ 通信连接维护是面向通信的两个端点的，而不考虑中间网段和节点。

为满足 TCP 协议的这些特点，TCP 协议做了如下的规定：
>+ **数据分片**：在发送端对用户数据进行分片，在接收端进行重组，由 TCP 确定分片的大小并控制分片和重组；
>+ **到达确认**：接收端接收到分片数据时，根据分片数据序号向发送端发送一个确认；
>+ **超时重发**：发送方在发送分片时启动超时定时器，如果在定时器超时之后没有收到相应的确认，重发分片；
>+ **滑动窗口**：TCP 连接每一方的接收缓冲空间大小都固定，接收端只允许另一端发送接收端缓冲区所能接纳的数据，TCP 在滑动窗口的基础上提供流量控制，防止较快主机致使较慢主机的缓冲区溢出；
>+ **失序处理**：作为 IP 数据报来传输的 TCP 分片到达时可能会失序，TCP 将对收到的数据进行重新排序，将收到的数据以正确的顺序交给应用层；
>+ **重复处理**：作为 IP 数据报来传输的 TCP 分片会发生重复，TCP 的接收端必须丢弃重复的数据；
>+ **数据校验**：TCP 将保持它首部和数据的检验和，这是一个端到端的检验和，目的是检测数据在传输过程中的任何变化。如果收到分片的检验和有差错，TCP 将丢弃这个分片，并不确认收到此报文段导致对端超时并重发。

**序列号与确认应答**：
<div align=center><img src="picture/序列号与确认应答.png"></div>

**建立连接**：
当主动方发出 SYN 连接请求后，等待对方回答 SYN+ACK，并最终对对方的 SYN 执行 ACK 确认。
>+ 1.客户端发送 SYN (SEQ=x) 报文给服务器端，进入 SYN_SEND 状态。
>+ 2.服务器端收到 SYN 报文，回应一个 SYN (SEQ=y) ACK (ACK=x+1) 报文，进入 SYN_RECV 状态。
>+ 3.客户端收到服务器端的 SYN 报文，回应一个 ACK (ACK=y+1) 报文，进入 Established 状态。

<div align=center><img src="https://gimg2.baidu.com/image_search/src=http%3A%2F%2Fimg2018.cnblogs.com%2Fblog%2F1517606%2F201811%2F1517606-20181118160849602-246785139.png&refer=http%3A%2F%2Fimg2018.cnblogs.com&app=2002&size=f9999,10000&q=a80&n=0&g=0n&fmt=jpeg?sec=1618540138&t=0fbe6ad6fd6d94ba6712d1621714cd26" width="70%" height="70%"></div>

**连接终止**：
建立一个连接需要三次握手，而终止一个连接要经过四次握手，这是由 TCP 的半关闭 (half-close) 造成的。
>+ 1.某个应用进程首先调用 close，称该端执行  “主动关闭” (active close)。该端的 TCP 于是发送一个 FIN 分节，表示数据发送完毕。
>+ 2.接收到这个 FIN 的对端执行  “被动关闭” (passive close)，这个 FIN 由 TCP 确认。
>+ 3.一段时间后，接收到这个文件结束符的应用进程将调用 close 关闭它的套接字。这导致它的 TCP 也发送一个 FIN。
>+ 4.接收这个最终 FIN 的原发送端 TCP (即执行主动关闭的那一端) 确认这个 FIN。

在步骤 2 与步骤 3 之间，从执行被动关闭一端到执行主动关闭一端流动数据是可能的，这称为 “半关闭” (half-close)。

<div align=center><img src="https://gimg2.baidu.com/image_search/src=http%3A%2F%2Fimg2018.cnblogs.com%2Fblog%2F1454579%2F201811%2F1454579-20181117232800366-2596210.png&refer=http%3A%2F%2Fimg2018.cnblogs.com&app=2002&size=f9999,10000&q=a80&n=0&g=0n&fmt=jpeg?sec=1618540277&t=bd247afc6306f1366585fad6c1083567" width="80%" height="80%"></div>

**最大报文长度**：
>+ TCP 在传送大量数据时，是以 MSS 的大小将数据进行分割发送。进行重发时也是以 MSS 为单位。
>+ MSS 是在三次握手的时候，在两端主机之间被计算得出。两端的主机在发出建立连接的请求时，会在 TCP 首部中写人 MSS 选项，告诉对方自己的接口能够适应的 MSS 的大小。然后会在两者之间选择一个较小的值投入使用。

**滑动窗口机制**: 
>+ 滑动窗口机制是 CP 的一种流量控制方法，该机制允许发送方在停止并等待确认前连续发送多个分组，而不必每发送一个分组就停下来等待确认，从而增加数据传输的速率提高应用的吞吐量。
>+ 发送方要知道接收方的接收窗口和网络这两个限制因素中哪一个更严格，然后在其限制范围内尽可能多发包。这个一口气能发送的数据量就是传说中的 TCP 发送窗口。

<div align=center><img src="https://images2015.cnblogs.com/blog/569491/201601/569491-20160107170203028-902842864.png"></div>

上图过程：
>+ 1.首先是 AB 之间三次握手建立 TCP 连接。在报文的交互过程中，A 将自己的缓冲区大小 (窗口大小) 3 发送给 B，B 同理，这样双方就知道了对端的窗口大小。
>+ 2.A 开始发送数据，A 连续发送 3 个单位的数据，因为他知道 B 的缓冲区大小。在这一波数据发送完后，A 就不能再发了，需等待 B 的确认。
>+ 3.A 发送过来的数据逐渐将缓冲区填满。
>+ 4.这时候缓冲区中的一个报文被进程读取，缓冲区有了一个空位，于是 B 向 A 发送一个 ACK，这个报文中指示窗口大小为 1。A 收到 B 发过来的 ACK 消息，并且知道 B 将窗口大小调整为 1，因此他只发送了一个单位的数据并且等待 B 的下一个确认报文。
>+ 5.如此反复。

**流量控制**：tcp 协议会根据接收方的处理速度来调整发送端的发送速度，这个机制叫流量控制。接受方会将自己可以接受的缓冲区大小放入头部的窗口大小字段，发送 ACK 确认的时候告知发送端；窗口越大说明网络吞吐量越高，如果发送端发现自己缓冲区快满了，就会缩小窗口大小；如果接收方处理不过来，缓冲区满了，就会把窗口大小设置为 0；随后发送端会暂停发送，但是会定期发送探测请求，等接收端告知窗口大小；实际的窗口大小计算方法：在选项中会有 1 个窗口扩大因子选项 M，实际的窗口大小是报文窗口大小左移 M 位，左移 1 位相当于 *2 倍；

(**零窗口 (TCP Zero Window)**: 在接收方窗口大小变为 0 的时候，发送方就不能再发送数据了。但是当接收方窗口恢复的时候发送方要怎么知道呢？在这个时候 TCP 会启动一个零窗口 (TCP Zero Window) 定时探测器，向接收方询问窗口大小，当接收方窗口恢复的时候，就可以再次发送数据。)

**超时重传**：在发送一个数据之后，就开启一个定时器，若是在这个时间内没有收到发送数据的 ACK 确认报文，则对该报文进行重传，在达到一定次数还没有成功时放弃并发送一个复位信号。

<div align=center><img src="https://images2018.cnblogs.com/blog/1233668/201806/1233668-20180613233505890-1600510236.png" width="70%" height="70%"></div>

定时器的时间 (RTO)。实际中 RTO 是根据网络中的 RTT (传输往返时间) 来自适应调整的。(每次发包时都会计算往返时间及其偏差 (RTT)。将这个往返时间和偏差相加，重发超时的时间就是比这个总和要稍大一点的值。)

此外，数据也不会被无限、反复地重发。达到一定重发次数之后，如果仍没有任何确认应答返回，就会判断为网络或对端主机发生了异常，强制关闭连接。并且通知应用通信异常强行终止。

**拥塞控制**：在某段时间，若对网络中某一资源的需求超过了该资源所能提供的可用部分，网络性能就要变坏，这种情况就叫做网络拥塞。在计算机网络中数位链路容量 (即带宽)、交换结点中的缓存和处理机等，都是网络的资源。若出现拥塞而不进行控制，整个网络的吞吐量将随输入负荷的增大而下降。

TCP 的四种拥塞控制算法：**慢开始 (慢启动)**、**拥塞控制**、**快重传**、**快恢复**。

<div align=center><img src="https://img2020.cnblogs.com/blog/698840/202006/698840-20200617173020468-958774006.png" width="100%" height="100%"></div>

**慢开始**：假设当前发送方拥塞窗口 cwnd 的值为 1，而发送窗口 swnd 等于拥塞窗口 cwnd，因此发送方当前只能发送一个数据报文段 (拥塞窗口 cwnd 的值是几，就能发送几个数据报文段)，接收方收到该数据报文段后，给发送方回复一个确认报文段，发送方收到该确认报文后，将拥塞窗口的值变为2。随着包的每次往返，拥塞窗口也会以 1、2、4 等进行指数增长。

**拥塞避免**：也就是每个传输轮次，拥塞窗口 cwnd 只能线性加 1，而不是像慢开始算法时，每个传输轮次，拥塞窗口 cwnd 按指数增长。同理，16+1……直至到达 24，假设 24 个报文段在传输过程中丢失 4 个，接收方只收到 20 个报文段，给发送方依次回复 20 个确认报文段，一段时间后，丢失的 4 个报文段的重传计时器超时了，发送发判断可能出现拥塞，更改 cwnd 和 ssthresh。并重新开始慢开始算法。

<div align=center><img src="https://img2020.cnblogs.com/blog/698840/202006/698840-20200617173202786-281437807.png" width="100%" height="100%"></div>

<div align=center><img src="https://img2020.cnblogs.com/blog/698840/202006/698840-20200617173219495-378880520.png" width="100%" height="100%"></div>

**快速重传**：快重传算法首先要求接收方每收到一个失序的报文段后就立即发出重复确认 (为的是使发送方及早知道有报文段没有到达对方) 而不要等到自己发送数据时才进行捎带确认。由于 TCP 采用的是累计确认机制，即当接收端收到比期望序号大的报文段时，便会重复发送最近一次确认的报文段的确认信号，我们称之为冗余 ACK (duplicate ACK)。如果在超时重传定时器溢出之前，接收到连续的三个重复冗余 ACK (其实是收到 4 个同样的 ACK，第一个是正常的，后三个才是冗余的)，发送端便知晓哪个报文段在传输过程中丢失了，于是重发该报文段，不需要等待超时重传定时器溢出，大大提高了效率。这便是快速重传机制。

<div align=center><img src="https://img2020.cnblogs.com/blog/698840/202006/698840-20200617173330287-864682842.png" width="100%" height="100%"></div>

(**为什么是 3 次冗余 ACK?** 首先要明白一点，即使发送端是按序发送，由于 TCP 包是封装在 IP 包内，IP 包在传输时乱序，意味着 TCP 包到达接收端也是乱序的，乱序的话也会造成接收端发送冗余 ACK。那发送冗余 ACK 是由于乱序造成的还是包丢失造成的，这里便需要好好权衡一番，因为把 3 次冗余 ACK 作为判定丢失的准则其本身就是估计值)。

**快速恢复**：当发送方连续收到三个重复确认，就执行 “乘法减小” 算法，把慢开始门限 ssthresh 减半。这是为了预防网络发生拥塞。(请注意：接下去不执行慢开始算法)。由于发送方现在认为网络很可能没有发生拥塞，因此与慢开始不同之处是现在不执行慢开始算法 (即拥塞窗口 cwnd 现在不设置为 1)，而是把 cwnd 值设置为慢开始门限 ssthresh 减半后的数值，然后开始执行拥塞避免算法 ( “加法增大” )，使拥塞窗口缓慢地线性增大。

<div align=center><img src="https://img2020.cnblogs.com/blog/698840/202006/698840-20200617173345073-2059012831.png" width="100%" height="100%"></div>

(**Nagle 算法**。是为了减少广域网的小分组数目，从而减小网络拥塞的出现；该算法要求一个 tcp 连接上最多只能有一个未被确认的未完成的小分组，在该分组 ack 到达之前不能发送其他的小分组，tcp 需要收集这些少量的分组，并在 ack 到来时以一个分组的方式发送出去；其中小分组的定义是小于 MSS 的任何分组；该算法的优越之处在于它是自适应的，确认到达的越快，数据也就发哦送的越快；而在希望减少微小分组数目的低速广域网上，则会发送更少的分组；)

**延迟确认应答**。事实上，大可不必为每一个数据段都进行一次确认应答。TCP采用滑动窗口的控制机制，因此通常确认应答少一些也无妨。**延迟机制**：在没有收到 2x最大段长度的数据为止不做确认应答 (根据操作系统的不同，有时也有不论数据大小，只要收到两个包就即刻返回确认应答的情)；其他情况下，最大延迟 0.5 秒发送确认应答 (很多操作系统设置为 0.2 秒左右)。

(**延迟 ACK 好处：**
>+ (1) 避免糊涂窗口综合症 (糊涂窗口综合症是指当发送端应用进程产生数据很慢、或接收端应用进程处理接收缓冲区数据很慢，或二者兼而有之；就会使应用进程间传送的报文段很小，特别是有效载荷很小； 极端情况下，有效载荷可能只有 1 个字节；传输开销有 40 字节 (20 字节的 IP 头 + 20 字节的 TCP 头) 这种现象。)；
>+ (2) 发送数据的时候将 ack 捎带发送，不必单独发送 ack；
>+ (3) 如果延迟时间内有多个数据段到达，那么允许协议栈发送一个 ack 确认多个报文段；)

(**当 Nagle 遇上延迟 ACK**：试想如下典型操作，写-写-读，即通过多个写小片数据向对端发送单个逻辑的操作，两次写数据长度小于 MSS，当第一次写数据到达对端后，对端延迟 ack，不发送 ack，而本端因为要发送的数据长度小于 MSS，所以 nagle 算法起作用，数据并不会立即发送，而是等待对端发送的第一次数据确认 ack；这样的情况下，需要等待对端超时发送 ack，然后本段才能发送第二次写的数据，从而造成延迟。)

**捎带应答**：TCP 的确认应答和回执数据可以通过一个包发送。这种方式叫做捎带应答 (PiggyBack Acknowledgement)。通过这种机制，可以使收发的数据量减少。也就是说，如果没有启用延迟确认应答就无法实现捎带应答。延迟确认应答是能够提高网络利用率从而降低计算机处理负荷的一种较优的处理机制。

<div align=center><img src="picture/TCP首部.png" width="100%" height="100%"></div>

另外，TCP 中没有表示包长度和数据长度的字段。可由 IP 层获知 TCP 的包长由 TCP 的包长可知数据的长度。
**TCP 首部格式**：
>+ **源端口号 (Source Port)**。表示发送端端口号。字段长 16 位。
>+ **目标端口号 (Destination Port)**。表示接收端端口号。字段长 16 位。
>+ **序列号 (Sequence Number)**。指发送数据的位置。每发送一次数据，就累加一次该数据字节数的大小。字段长 32 位。
>+ **确认应答号 (Acknowledgment Number)**。指下一次应该收到的数据的序列号。字段长 32 位。
>+ **数据偏移 (Data Offset)**。该字段表示 TCP 所传输的数据部分应该从 TCP 包的哪个位开始计算，当然也可以把它看作 TCP 首部的长度。字段长 4 位。
>+ **保留 (Reserved)**。为了以后扩展使用。字段长 4 位。
>+ **控制位 (Control Flag)**。字段长 8 位。从左至右分别为 CWR(通知对方已将拥塞窗口缩小)、ECE(通知对方从对方到这边的网络有拥塞)、URG(表示包中有需要紧急处理的数据)、ACK(确认应答的字段变为有效)、PSH(表示需要将收到的数据立刻传给上层应用协议)、RST(表示连接出现异常，必须断开连接)、SYN(表示希望建立连接，并在其序列号的字段进行序列号初始值的设定)、FIN(表示不会再有数据发送，希望断开连接)。
>+ **窗口大小 (Window Size)**。用于通知从相同 TCP 首部的确认应答号所指位置开始能够接收的数据大小 (8位字节)。TCP不允许发送超过此处所示大小的数据。不过，如果窗口为 0，则表示可以发送窗口探测，以了解最新的窗口大小。但这个数据必须是 1 个字节。该字段长为16位。
>+ **校验和 (Checksum)**。判断协议首部和数据是否被破坏。
>+ **紧急指针 (Urgent Pointer)**。只有在 URG 控制位为 1 时有效。该字段的数值表示本报文段中紧急数据的指针。正确来讲，从数据部分的首位到紧急指针所指示的位置为止为紧急数据。因此也可以说紧急指针指出了紧急数据的末尾在报文段中的位置。该字段长为 16 位。
>+ **选项 (Options)**。选项字段用于提高 TCP 的传输性能。因为根据数据偏移 (首部长度) 进行控制，所以其长度最大为 40 字节。

最大吞吐量T = 窗口大小W / 往返时间RTT 

<font face="黑体" color=#556B2F size=5>UDP</font>
<font face="黑体" color=#8FBC8F size=4>(User Datagram Protocol)</font>

UDP 是 User Datagram Protocol 的简称，中文名是用户数据报协议，是 OSI (Open System Interconnection，开放式系统互联) 参考模型中一种无连接的传输层协议，提供面向事务的简单不可靠信息传送服务，简单高效。它不提供报文到达确认、排序、及流量控制等功能。

许多应用只支持 UDP，如：多媒体数据流，不产生任何额外的数据，即使知道有破坏的包也不进行重发。当强调传输性能而不是传输的完整性时，如：音频和多媒体应用，UDP 是最好的选择。在数据传输时间很短，以至于此前的连接过程成为整个流量主体的情况下，UDP 也是一个好的选择。

**应用**：
>+ 包总量较少的通信 (DNS、SNMP等)
>+ 视频、音频等多媒体通信 (即时通信)
>+ 限定于 LAN 等特定网络中的应用通信
>+ 广播通信 (广播、多播)

**TCP和UDP的比较**:
<div align=center><img src="picture/TCP与UDP对比.png" width="100%" height="100%"></div>

<div align=center><img src="picture/UDP首部.png" width="100%" height="100%"></div>

**UDP 首部格式**：
>+ **源端口号 (Source Port)**。表示发送端端口号。字段长 16 位。
>+ **目标端口号 (Destination Port)**。表示接收端端口号。字段长 16 位。
>+ **包长度 (Length)**。该字段保存了 UDP 首部的长度跟数据的长度之和。
>+ **校验和 (Checksum)**。校验和是为了提供可靠的 UDP 首部和数据而设计。

<font face="黑体" color=#556B2F size=5>其他传输层协议</font>

**UDP-Lite (Lightweight User Datagram Protocol)**：轻量级用户数据报协议。传统的 UDP 协议是对其载荷 (Payload) 进行完整的校验的，如果其中的一些位 (哪怕只有一位) 发生了变化，那么整个数据包都有可能被丢弃，在某些情况下，丢掉这个包的代价是非常大的，尤其当包比较大的时候。在 UDP-Lite 协议中，一个数据包到底需不需要对其载荷进行校验，或者是校验多少位都是由用户控制的 (这是这种可选择性，其实 udp-lite 的代码实现是比 udp 复杂的，though 字面上有个 lite)，并且 UDP-Lite 协议就是用 UDP 协议的 Length 字段来表示其 Checksum Coverage 的，所以当 UDP-Lite 协议的 Checksum Coverage 字段等于整个 UDP 数据包 (包括 UDP 头和载荷) 的长度时，UDP-Lite 产生的包也将和传统的UDP包一模一样。

**SCTP (Stream Control Transmission Protocol)**：流控制传输协议。
>+ 1.TCP 是以字节为单位传输的，SCTP 是以数据块为单位传输的 (面向消息)。
>+ 2.TCP 通常是单路径传输，SCTP 可以多路径传输。
>+ 3.TCP 是单流有序传输，SCTP 可以多流独立有序/无序传输。
>+ 4.TCP 连接的建立过程需要三步握手，SCTP 连接的建立过程需要四步握手。
>+ 5.SCTP 有 heartbeat 机制来管理路径的可用性。

**DCCP (Datagram Congestion Control Protocol)**：数据报拥塞控制协议。是一个辅助 UDP 的崭新的传输层协议。UDP 没有拥塞控制机制。为此，当应用使用 UDP 发送大量数据包时极容易出现问题。互联网中的通信，即使使用 UDP 也应该控制拥塞。而这个机制开发人员很难将其融合至协议中，于是便出现了 DCCP 这样的规范。

DCCP 具有如下几个特点:
>+ 1.与 UDP 一样，不能提供发送数据的可靠性传输。
>+ 2.它面向连接，具备建立连接与断开连接的处理。在建立和断开连接上是具有可靠性。
>+ 3.能够根据网络拥堵情况进行拥塞控制。使用 DCCP 应用可以根据自身特点选择两种方法进行拥塞控制。它们分别是 “类似 TCP (TCP-Like) 拥塞控制” 和“TCP 友好升级控制” (TCP-Friendly Rate Control)。
>+ 4.为了进行拥塞控制，接收端收到包以后返回确认应答 (ACK)。该确认应答将被用于重发与否的判断。

# 5.路由协议

路由器根据路由控制表 (Routing Table) 转发数据包。它根据所收到的数据包中目标主机的 IP 地址与路由控制表的比较得出下一个应该接收的路由器。因此，这个过程中路由控制表的记录一定要正确无误。但凡出现错误，数据包就有可能无法到达目标主机。

路由控制分为静态和动态两种类型。**静态路由**是指事先设置好路由器和主机中并将路由信息固定的一种方法。而**动态路由**是指让路由协议在运行过程中自动地设置路由控制信息的一种方法。这些方法都有它们各自的利弊。

<div align=center><img src="picture/静态路由与动态路由.png" width="100%" height="100%"></div>

动态路由如下图所示，会给相邻路由器发送自己已知的网络连接信息，而这些信息又像接力一样依次传递给其他路由器，直至整个网络都了解时，路由控制表也就制作完成了。而此时也就可以正确转发 IP 数据包了。

<div align=center><img src="picture/动态路由.png" width="100%" height="100%"></div>

制定自己的路由策略，并以此为准在一个或多个网络群体中采用的小型单位叫做**自治系统** (AS: Autonomous System) 或**路由选择域** (Routing Domain)。

<div align=center><img src="picture/EGP与IGP.png" width="100%" height="100%"></div>

自治系统 (路由选择域) 内部动态路由采用的协议是域内路由协议，即 IGP。而自治系统之间的路由控制采用的是域间路由协议，即 EGP。

**路由算法**：
>+ **距离向量算法** (Distance-Vector)。路由器之间可以互换目标网络的方向及其距离的相关信息，并以这些信息为基础制作路由控制表。这种方法在处理上比较简单，不过由于只有距离和方向的信息，所以当网络构造变得分外复杂时，在获得稳定的路由信息之前需要消耗一定时间，也极易发生路由循环等问题。
>+ **链路状态算法** (Link-State)。链路状态算法以图论作为理论基础，用图来表示网络拓扑结构，并利用图论中的最短路径算法来计算网络间的最佳路由，因此链路状态算法又被称作最短路径优先算法 SPF。链路状态算法的思想是要求网络中所有参与链路状态路由协议的路由器都掌握网络的全部拓扑结构信息，并记录在路由数据库中。链路状态算法中路由数据库实质上是一个网络结构的拓扑图，该拓扑图由一个节点的集合和一个边的集合构成。在网络拓扑图中，结点代表网络中路由器，边代表路由器之间的物理链路。在网络拓扑结构图中，每一条链路上可以附加不同的属性，例如链路的状态、距离或费用等。如果每一个路由器所保存的网络拓扑结构图都是一致的，那么个路由器生成的路由表也是最佳的，不存在错误路由或循环路由。

**区别**：
>+ 1.与距离向量算法相比，链路状态算法具有更快的收敛速度。
>+ 2.链路状态算法具有更好的功能扩展能力，很容易地在链路状态中加入新的属性和参数，而无需改变路由交换的规则，是路由计算中能够引用不同的参数来实现新的功能。
>+ 3.链路状态算法还提供了更好的在规模上的可升级性，链路状态算法允许在一个大型网络中划分选路层次。
>+ 4.链路状态算法每个路由器需要有较大的存储空间，用以存储所收到的每一个节点的链路状态分组；计算工作量大，每次都必须计算最短路径。

<div align=center><img src="picture/主要路由算法.png" width="100%" height="100%"></div>

<font face="黑体" color=#556B2F size=5>RIP</font>
<font face="黑体" color=#8FBC8F size=4>(Routing Information Protocol，路由信息协议)</font>

路由信息协议 (RIP) 是内部网关协议 IGP 中最先得到广泛使用的协议。RIP是一种分布式的基于距离矢量的路由选择协议，是因特网的标准协议，其最大优点就是实现简单，开销较小。

同一自治系统 (AS) 中的路由器每 30 秒会与相邻的路由器交换子讯息，以动态的建立路由表。RIP 允许最大的 hop数 (跳数）为 15 多于 15 跳不可达。

**RIP 的特点**：
>+ （1）仅和相邻的路由器交换信息。如果两个路由器之间的通信不经过另外一个路由器，那么这两个路由器是相邻的。RIP 协议规定，不相邻的路由器之间不交换信息。
>+ （2）路由器交换的信息是当前本路由器所知道的全部信息。即自己的路由表。
>+ （3）按固定时间交换路由信息，如，每隔 30 秒，然后路由器根据收到的路由信息更新路由表。（也可进行相应配置使其触发更新）

**RIP 的局限**：
>+ （1）过于简单，以跳数为依据计算度量值，经常得出非最优路由。例如：2 跳 64K 专线，和 3 跳 1000M 光纤，显然多跳一下没什么不好。
>+ （2）度量值以 16 为限，不适合大的网络。解决路由环路问题，16 跳在 rip 中被认为是无穷大，rip 是一种域内路由算法自治路由算法，多用于园区网和企业网。
>+ （3）安全性差，接受来自任何设备的路由更新。无密码验证机制，默认接受任何地方任何设备的路由更新。不能防止恶意的 rip 欺骗。
>+ （4）不支持无类 ip 地址和 VLSM<ripv1>。
>+ （5）收敛性差，时间经常大于 5 分钟。
>+ （6）消耗带宽很大。完整的复制路由表，把自己的路由表复制给所有邻居，尤其在低速广域网链路上更以显式的全量更新。

**RIP 的破环机制**：
>+ **水平分割**：从一接口进来路由更新是不会再从该接口发送的。
>+ **毒性逆转水平分割**：触发更新，使用 16 跳的触发路由来告知邻居，邻居不可达，之后邻居返还该路由来表示确认收到。
>+ **跳数限制**：最大 15 跳，16 跳不可达
>+ **抑制计时器**：当收到路由跳数增加，则判定该路由条目可能出环，在 180S 内再次受到跳数增加后的路由，则抑制该条目不接受更新。注：触发条件：1. 失效计时器 Possibly down 2.重新从任意接口收到该路由

<font face="黑体" color=#556B2F size=5>OSPF</font>
<font face="黑体" color=#8FBC8F size=4>(Open Shortest Path First，开放最短路径优先)</font>

OSPF 路由协议是一种典型的链路状态 (Link-state) 的路由协议，一般用于同一个路由域内。在这里，路由域是指一个自治系统 (Autonomous System)，即 AS，它是指一组通过统一的路由政策或路由协议互相交换路由信息的网络。在这个 AS 中，所有的 OSPF 路由器都维护一个相同的描述这个 AS 结构的数据库，该数据库中存放的是路由域中相应链路的状态信息，OSPF 路由器正是通过这个数据库计算出其 OSPF 路由表的。

OSPF 的简单说就是两个相邻的路由器通过发报文的形式成为邻居关系，邻居再相互发送链路状态信息形成邻接关系，之后各自根据最短路径算法算出路由，放在 OSPF 路由表，OSPF 路由与其他路由比较后优的加入全局路由表。整个过程使用了五种报文、三个阶段、四张表。

**五种报文**：
>+ **Hello 报文**：建立并维护邻居关系。
>+ **DBD 报文**：发送链路状态头部信息。
>+ **LSR 报文**：把从 DBD 中找出需要的链路状态头部信息传给邻居，请求完整信息。
>+ **LSU 报文**：将 LSR 请求的头部信息对应的完整信息发给邻居。
>+ **LSACK 报文**:收到 LSU 报文后确认该报文。

**三个阶段**：
>+ **邻居发现**：通过发送 Hello 报文形成邻居关系。
>+ **路由通告**：邻居间发送链路状态信息形成邻接关系。
>+ **路由计算**：根据最短路径算法算出路由表。

**四张表**：
>+ **邻居表**：主要记录形成邻居关系路由器。
>+ **链路状态数据库**：记录链路状态信息。
>+ **OSPF路由表**：通过链路状态数据库得出。
>+ **全局路由表**：OSPF 路由与其他比较得出

**工作过程**：
>+ (1)**了解自身链路**。每台路由器了解其自身的链路，即与其直连的网络。 
>+ (2)**寻找邻居**。不同于RIP，OSPF协议运行后，并不立即向网络广播路由信息，而是先寻找网络中可与自己交换链路状态信息的周边路由器。可以交互链路状态信息的路由器互为邻居。
>+ (3)**创建链路状态数据包**。路由器一旦建立了邻居关系，就可以创建链路状态数据包。
>+ (4)**链路状态信息传递**。路由器将描述链路状态的LSA泛洪到邻居，最终形成包含网络完整链路状态信息的链路状态数据库。
>+ (5)**计算路由**。路由区域内的每台路由器都可以使用SPF算法来独立计算路由。

OSPF 中划分区域的目的就是在于控制链路状态信息 LSA 泛洪的范围、减小链路状态数据库 LSDB 的大小、改善网络的可扩展性、达到快速地收敛。
>+ **骨干区域**：作为中央实体，其他区域与之相连，骨干区域编号为 0，在该区域中，各种类型的 LSA 均允许发布。
>+ **标准区域**：除骨干区域外的默认的区域类型，在该类型区域中，各种类型的 LSA 均允许发布。
>+ **末梢区域**：即 STUB 区域，该类型区域中不接受关于 AS 外部的路由信息，即不接受类型 5 的 AS 外部 LSA，需要路由到自治系统外部的网络时，路由器使用缺省路由（0.0.0.0），末梢区域中不能包含有自治系统边界路由器 ASBR。 
>+ **完全末梢区域**：该类型区域中不接受关于 AS 外部的路由信息，同时也不接受来自 AS 中其他区域的汇总路由，即不接受类型 3、类型 4、类型 5 的 LSA，完全末梢区域也不能包换有自治系统边界路由器 ASBR。

**OSPF协议主要优点**：
>+ （1）**OSPF 适合在大范围的网络**：OSPF 协议当中对于路由的跳数，它是没有限制的，所以 OSPF 协议能用在许多场合，同时也支持更加广泛的网络规模。只要是在组播的网络中，OSPF 协议能够支持数十台路由器一起运作。
>+ （2）**组播触发式更新**：OSPF 协议在收敛完成后，会以触发方式发送拓扑变化的信息给其他路由器，这样就可以减少网络宽带的利用率；同时，可以减小干扰，特别是在使用组播网络结构，对外发出信息时，它对其他设备不构成其他影响
>+ （3）**收敛速度快**：如果网络结构出现改变，OSPF 协议的系统会以最快的速度发出新的报文，从而使新的拓扑情况很快扩散到整个网络；而且，OSPF 采用周期较短的 HELLO 报文来维护邻居状态。
>+ （4）**以开销作为度量值**：OSPF 协议在设计时，就考虑到了链路带宽对路由度量值的影响。OSPF 协议是以开销值作为标准，而链路开销和链路带宽，正好形成了反比的关系，带宽越是高，开销就会越小，这样一来，OSPF 选路主要基于带宽因素。
>+ （5）**OSPF 协议的设计是为了避免路由环路**：在使用最短路径的算法下，收到路由中的链路状态，然后生成路径，这样不会产生环路。
>+ （6）**应用广泛**：广泛的应用在互联网上，其他会有大量的应用实例。证明这是使用最广泛的 IGP 之一。

<font face="黑体" color=#556B2F size=5>BGP</font>
<font face="黑体" color=#8FBC8F size=4>(Border Gateway Protocol，边界网关协议)</font>

边界网关协议BGP (Border Gateway Protocol) 是一种实现自治系统 AS (Autonomous System) 之间的路由可达，并选择最佳路由的距离矢量路由协议。

**BGP分类**：BGP 按照运行方式分为 EBGP (External/Exterior BGP) 和 IBGP (Internal/Interior BGP) 。
>+ **EBGP**：运行于不同 AS 之间的 BGP 称为EBGP。为了防止 AS 间产生环路，当 BGP 设备接收 EBGP 对等体发送的路由时，会将带有本地 AS 号的路由丢弃。
>+ **IBGP**：运行于同一 AS 内部的 BGP 称为 IBGP。为了防止 AS 内产生环路，BGP 设备不将从 IBGP 对等体学到的路由通告给其他 IBGP 对等体，并与所有 IBGP 对等体建立全连接。为了解决 IBGP 对等体的连接数量太多的问题，BGP 设计了路由反射器和 BGP 联盟。

**BGP 报文交互中的角色**：
>+ **Speaker**：发送 BGP 报文的设备称为 BGP 发言者 (Speaker)，它接收或产生新的报文信息，并发布 (Advertise) 给其它 BGP Speaker。
>+ **Peer**：相互交换报文的 Speaker 之间互称对等体 (Peer)。若干相关的对等体可以构成对等体组 (Peer Group)。

**BGP 的报文**：BGP 对等体间通过以下 5 种报文进行交互，其中 Keepalive 报文为周期性发送，其余报文为触发式发送：
>+ **Open报文**：用于建立 BGP 对等体连接。
>+ **Update报文**：用于在对等体之间交换路由信息。
>+ **Notification报文**：用于中断 BGP 连接。
>+ **Keepalive报文**：用于保持 BGP 连接。
>+ **Route-refresh报文**：用于在改变路由策略后请求对等体重新发送路由信息。只有支持路由刷新 (Route-refresh) 能力的 BGP 设备会发送和响应此报文。

<font face="黑体" color=#556B2F size=5>MPLS</font>
<font face="黑体" color=#8FBC8F size=4>(Multi-Protocol Label Switching，多协议标签交换)</font>

MPLS 是一种在开放的通信网上利用标签引导数据高速、高效传输的新技术。多协议的含义是指 MPLS 不但可以支持多种网络层层面上的协议，还可以兼容第二层的多种数据链路层技术。

**工作过程**：
>+ 1．LDP 和传统路由协议 (如 OSPF、ISIS 等) 一起，在各个 LSR 中为有业务需求的 FEC 建立路由表和标签映射表。
>+ 2．入节点 Ingress 接收分组，完成第三层功能，判定分组所属的 FEC，并给分组加上标签，形成 MPLS 标签分组，转发到中间节点 Transit。
>+ 3．Transit 根据分组上的标签以及标签转发表进行转发，不对标签分组进行任何第三层处理。
>+ 4．在出节点 Egress 去掉分组中的标签，继续进行后面的转发。

**LSR (Label Switching Router)**：标记交换路由器

**LER (Label Edge Router)**：标记边缘路由器

<div align=center><img src="picture/MPLS.png" width="100%" height="100%"></div>

由此可以看出，MPLS 并不是一种业务或者应用，它实际上是一种隧道技术，也是一种将标签交换转发和网络层路由技术集于一身的路由与交换技术平台。这个平台不仅支持多种高层协议与业务，而且，在一定程度上可以保证信息传输的安全性。

# 6. 应用协议

<font face="黑体" color=#556B2F size=5>远程登录</font>

实现从自己的本地计算机登录到网络另一端计算功能的应用就叫做**远程登录**。

**TELNET**

为用户提供了在本地计算机上完成远程主机工作的能力。在终端使用者的电脑上使用 telnet 程序，用它连接到服务器。终端使用者可以在 telnet 程序中输入命令，这些命令会在服务器上运行，就像直接在服务器的控制台上输入一样。可以在本地就能控制服务器。

Telnet 远程登录服务分为以下 4 个过程：
>+ 1）本地与远程主机建立连接。该过程实际上是建立一个 TCP 连接，用户必须知道远程主机的 Ip 地址或域名；
>+ 2）将本地终端上输入的用户名和口令及以后输入的任何命令或字符以 NVT (Net Virtual Terminal) 格式传送到远程主机。该过程实际上是从本地主机向远程主机发送一个 IP 数据包；
>+ 3）将远程主机输出的 NVT 格式的数据转化为本地所接受的格式送回本地终端，包括输入命令回显和命令执行结果；
>+ 4）最后，本地终端对远程主机进行撤消连接。该过程是撤销一个 TCP 连接。

Telnet 提供了 3 种基本服务：
>+ 1）Telnet 定义一个网络虚拟终端为远程系统提供一个标准接口。客户机程序不必详细了解远程系统，他们只需构造使用标准接口的程序；
>+ 2）Telnet 包括一个允许客户机和服务器协商选项的机制，而且它还提供一组标准选项；
>+ 3）Telnet 对称处理连接的两端，即 Telnet 不强迫客户机从键盘输入，也不强迫客户机在屏幕上显示输出。

**SSH**

SSH 为 Secure Shell 的缩写，由 IETF 的网络小组（Network Working Group）所制定；SSH 为建立在应用层基础上的安全协议。SSH 是较可靠，专为远程登录会话和其他网络服务提供安全性的协议。利用 SSH 协议可以有效防止远程管理过程中的信息泄露问题。SSH 最初是 UNIX 系统上的一个程序，后来又迅速扩展到其他操作平台。SSH 在正确使用时可弥补网络中的漏洞。

从客户端来看，SSH 提供两种级别的安全验证。第一种级别（基于口令的安全验证）；第二种级别（基于密匙的安全验证）。

SSH 还包括很多非常方便的功能: 可以使用更强的认证机制。可以转发文件。
可以使用端口转发功能。

<font face="黑体" color=#556B2F size=5>文件传输</font>

**FTP（File Transfer Protocol，文件传输协议）**

FTP 是通过怎样的机制才得以实现文件传输的呢? 它使用两条 TCP 连接:一条用来控制，另一条用于数据（文件）的传输。用于控制的 TCP 连接主要在 FTP 的控制部分使用。例如登录用户名和密码的验证、发送文件的名称、发送方式的设置。利用这个连接，可以通过 ASCII 码字符串发送请求和接收应答。在这个连接上无法发送数据，数据需要一个专门的 TCP 进行连接。

<div align=center><img src="picture/FTP.png" width="100%" height="100%"></div>

<font face="黑体" color=#556B2F size=5>电子邮件</font>

**MIME**：(Multipurpose Internet Mail Extensions) 多用途互联网邮件扩展类型。是设定某种扩展名的文件用一种应用程序来打开的方式类型，当该扩展名文件被访问的时候，浏览器会自动使用指定应用程序来打开。多用于指定一些客户端自定义的文件名，以及一些媒体文件打开方式。

**SMTP**：(Simple Mail Transfer Protocol) SMTP 是一种提供可靠且有效的电子邮件传输的协议。SMTP 是建立在 FTP 文件传输服务上的一种邮件服务，主要用于系统之间的邮件信息传递，并提供有关来信的通知。SMTP 独立于特定的传输子系统，且只需要可靠有序的数据流信道支持，SMTP 的重要特性之一是其能跨越网络传输邮件，即 “SMTP 邮件中继”。使用 SMTP，可实现相同网络处理进程之间的邮件传输，也可通过中继器或网关实现某处理进程与其他网络之间的邮件传输。SMTP协议的工作过程可分为如下 3 个过程：
>+ (1)建立连接：在这一阶段，SMTP 客户请求与服务器的25端口建立一个 TCP 连接。一旦连接建立，SMTP 服务器和客户就开始相互通告自己的域名，同时确认对方的域名。 
>+ (2)邮件传送：利用命令，SMTP 客户将邮件的源地址、目的地址和邮件的具体内容传递给 SMTP 服务器，SMTP 服务器进行相应的响应并接收邮件。
>+ (3)连接释放：SMTP 客户发出退出命令，服务器在处理命令后进行响应，随后关闭 TCP 连接。

**POP**：(Post Office Protocol，即邮局协议) POP 允许本地计算机上的用户代理程序连接到邮件服务器，将用户的邮件取回到本地，这样用户就能在本地阅读邮件了。本协议主要用于支持使用客户端远程管理在服务器上的电子邮件。POP 协议支持 “离线” 邮件处理。其具体过程是：邮件发送到服务器上，电子邮件客户端调用邮件客户机程序以连接服务器，并下载所有未阅读的电子邮件。这种离线访问模式是一种存储转发服务，将邮件从邮件服务器端送到个人终端机器上，一般是 PC 机或 MAC。一旦邮件发送到 PC 机或 MAC 上，邮件服务器上的邮件将会被删除。

**IMAP**：(Internet Message Access Protocol) 它与 POP3 协议的主要区别是用户可以不用把所有的邮件全部下载，可以通过客户端直接对服务器上的邮件进行操作。支持连接和断开两种操作模式。支持多个客户同时连接到一个邮箱。支持访问消息中的 MIME 部分和部分获取。支持在服务器保留消息状态信息。支持在服务器上访问多个邮箱。支持服务器端搜索。支持一个定义良好的扩展机制。

<font face="黑体" color=#556B2F size=5>WWW</font>

万维网 (www，World Wide Web) 是将互联网中的信息以超文本形式展现的系统。也叫做 Web。可以显示 WWW 信息的客户端软件叫做 Web 浏览器。

wWW 定义了3个重要的概念，它们分别是访问信息的手段与位置 (**URI**, Uniform Resource Identifier)、信息的表现形式 (**HTML**，HyperText Markup Language) 以及信息转发 (**HTTP**，HyperText Transfer Protocol) 等操作。

**CGI**: 公共网关接口（Common Gateway Interface，CGI）是 Web 服务器运行时外部程序的规范，按 CGI 编写的程序可以扩展服务器功能。CGI 应用程序能与浏览器进行交互，还可通过数据 API 与数据库服务器等外部数据源进行通信，从数据库服务器中获取数据。格式化为 HTML 文档后，发送给浏览器，也可以将从浏览器获得的数据放到数据库中。

**Cookie**: 某些网站为了辨别用户身份，进行Session跟踪而储存在用户本地终端上的数据（通常经过加密），由用户客户端计算机暂时或永久保存的信息。Cookie 是一个保存在客户机中的简单的文本文件, 这个文件与特定的 Web 文档关联在一起, 保存了该客户机访问这个 Web 文档时的信息, 当客户机再次访问这个 Web 文档时这些信息可供该文档使用。可以帮助我们实现记录用户个人信息的功能。

<font face="黑体" color=#556B2F size=5>网络管理</font>

TCP/IP网络管理协议标准框架可分为三大部分：
>+ （1）第一部分为网络管理协议（SNMP），主要涉及同信息通信相关的关系和消息流，定义了管理系统上运行的管理站软件如何与管理代理通信，包括两者之间交换的消息分组的格式、含义及名字与值的表示等，此外也定义了被管设备间的管理关系，即提供了管理系统的授权管理。SNMP 中管理端叫做管理器 (Manager，网络监控终端)，被管理端叫做代理 (路由器、交换机等)。决定管理器与代理之间的通信中所要交互信息的正是 SNMP。SNMP 中如果将 MIB 看做代理所管理的信息在数据库中的值，那么它可以新增一个值。
>+ （2）第二部分为管理信息结构（SMI，Structure of Management Information）是描述管理信息的标准符号，说明了定义和构造 MIB 的总体框架，以及数据类型的表示和命名方法。
>+ （3）第三部分为管理信息库（MIB，Management Information Base）。MIB 定义了受管设备必须保存的数据项、允许对每个数据项进行的操作及其含义，即管理系统可访问的受管设备的控制和状态信息等数据变量都保存在 MIB 中。MIB 定义的通用化格式支持对每一个新的被管理设备定义其特定的 MIB 组，因此厂家可以采用标准的方法定义其专用的管理对象，从而可以管理许多新协议和设备，可扩展性很好。

上述三部分相互独立，每部分都定义了单独标准（RFC）。SNMP 定义通信的方式和格式，但不指明具体设备上的具体数据，每种设备的数据细节在 MIB 中定义，这样做达到了 “控制与数据相分离” 的目的，能提供很好的兼容性和可扩展性。而 SMI 又为保持 MIB 的简单性和可扩展性提供了很好的支持。

# 7.网络安全

<font face="黑体" color=#556B2F size=5>SSL</font>

SSL (Secure Sockets Layer 安全套接字协议), 及其继任者传输层安全（Transport Layer Security，TLS）是为网络通信提供安全及数据完整性的一种安全协议。TLS 与 SSL 在传输层与应用层之间对网络连接进行加密。

SSL 协议位于 TCP/IP 协议与各种应用层协议之间，为数据通讯提供安全支持。SSL 协议可分为两层： 
>+ SSL记录协议（SSL Record Protocol）：它建立在可靠的传输协议（如TCP）之上，为高层协议提供数据封装、压缩、加密等基本功能的支持。 
>+ SSL握手协议（SSL Handshake Protocol）：它建立在 SSL 记录协议之上，用于在实际的数据传输开始前，通讯双方进行身份认证、协商加密算法、交换加密密钥等。

**服务器认证阶段**：
>+ 1）客户端向服务器发送一个开始信息 “Hello” 以便开始一个新的会话连接；
>+ 2）服务器根据客户的信息确定是否需要生成新的主密钥，如需要则服务器在响应客户的 “Hello” 信息时将包含生成主密钥所需的信息；
>+ 3）客户根据收到的服务器响应信息，产生一个主密钥，并用服务器的公开密钥加密后传给服务器；
>+ 4）服务器回复该主密钥，并返回给客户一个用主密钥认证的信息，以此让客户认证服务器。

**用户认证阶段**：在此之前，服务器已经通过了客户认证，这一阶段主要完成对客户的认证。经认证的服务器发送一个提问给客户，客户则返回（数字）签名后的提问和其公开密钥，从而向服务器提供认证。

SSL协议提供的安全通道有以下三个特性：
>+ 机密性：SSL 协议使用密钥加密通信数据。
>+ 可靠性：服务器和客户都会被认证，客户的认证是可选的。
>+ 完整性：SSL 协议会对传送的数据进行完整性检查。

<font face="黑体" color=#556B2F size=5>TLS</font>

TLS(Transport Layer Security Protocol)：安全传输层协议。安全传输层协议（TLS）用于在两个通信应用程序之间提供保密性和数据完整性。该协议由两层组成： TLS 记录协议（TLS Record）和 TLS 握手协议（TLS Handshake）。较低的层为 TLS 记录协议，位于某个可靠的传输协议（例如 TCP）上面。

TLS 记录协议提供的连接安全性具有两个基本特性：   
>+ 私有――对称加密用以数据加密（DES 、RC4 等）。对称加密所产生的密钥对每个连接都是唯一的，且此密钥基于另一个协议（如握手协议）协商。记录协议也可以不加密使用。   
>+ 可靠――信息传输包括使用密钥的 MAC 进行信息完整性检查。安全哈希功能（ SHA、MD5 等）用于 MAC 计算。记录协议在没有 MAC 的情况下也能操作，但一般只能用于这种模式，即有另一个协议正在使用记录协议传输协商安全参数。 

TLS 对于安全性的改进:
>+ 1）对于消息认证使用密钥散列法：TLS 使用“消息认证代码的密钥散列法”（HMAC），当记录在开放的网络（如因特网）上传送时，该代码确保记录不会被变更。SSLv3.0 还提供键控消息认证，但 HMAC 比 SSLv3.0 使用的（消息认证代码）MAC 功能更安全。
>+ 2）增强的伪随机功能（PRF）：PRF生成密钥数据。在 TLS 中，HMAC 定义 PRF。PRF 使用两种散列算法保证其安全性。如果任一算法暴露了，只要第二种算法未暴露，则数据仍然是安全的。
>+ 3）改进的已完成消息验证：TLS 和 SSLv3.0 都对两个端点提供已完成的消息，该消息认证交换的消息没有被变更。然而，TLS 将此已完成消息基于 PRF 和 HMAC 值之上，这也比 SSLv3.0 更安全。
>+ 4）一致证书处理：与 SSLv3.0 不同，TLS 试图指定必须在 TLS 之间实现交换的证书类型。
>+ 5）特定警报消息：TLS 提供更多的特定和附加警报，以指示任一会话端点检测到的问题。TLS 还对何时应该发送某些警报进行记录。

<font face="黑体" color=#556B2F size=5>HTTPS</font>

HTTPS （全称：Hyper Text Transfer Protocol over SecureSocket Layer），是以安全为目标的 HTTP 通道，在HTTP的基础上通过传输加密和身份认证保证了传输过程的安全性。HTTPS 在 HTTP 的基础下加入 SSL，HTTPS 的安全基础是 SSL，因此加密的详细内容就需要 SSL。 HTTPS 存在不同于 HTTP 的默认端口及一个加密/身份验证层（在 HTTP与 TCP 之间）。这个系统提供了身份验证与加密通讯方法。

**HTTP 的缺点**：其数据的明文传送和消息完整性检测的缺乏, 而这两点恰好是网络支付, 网络交易等新兴应用中安全方面最需要关注的。HTTP 在传输客户端请求和服务端响应时, 唯一的数据完整性检验就是在报文头部包含了本次传输数据的长度, 而对内容是否被篡改不作确认。 因此攻击者可以轻易的发动中间人攻击, 修改客户端和服务端传输的数据。

HTTPS 主要由两部分组成：HTTP + SSL / TLS，也就是在 HTTP 上又加了一层处理加密信息的模块。服务端和客户端的信息传输都会通过 TLS 进行加密，所以传输的数据都是加密后的数据。

**HTTP 原理**：
>+ 1.客户端的浏览器首先要通过网络与服务器建立连接，该连接是通过 TCP 来完成的，一般 TCP 连接的端口号是 80。 建立连接后，客户机发送一个请求给服务器，请求方式的格式为：统一资源标识符（URL）、协议版本号，后边是 MIME 信息包括请求修饰符、客户机信息和许可内容。
>+ 2.服务器接到请求后，给予相应的响应信息，其格式为一个状态行，包括信息的协议版本号、一个成功或错误的代码，后边是 MIME 信息包括服务器信息、实体信息和可能的内容。

**HTTPS 原理**:
>+ 1.客户端将它所支持的算法列表和一个用作产生密钥的随机数发送给服务器 ；
>+ 2.服务器从算法列表中选择一种加密算法，并将它和一份包含服务器公用密钥的证书发送给客户端；该证书还包含了用于认证目的的服务器标识，服务器同时还提供了一个用作产生密钥的随机数；
>+ 3.客户端对服务器的证书进行验证（有关验证证书，可以参考数字签名），并抽取服务器的公用密钥；然后，再产生一个称作 pre_master_secret 的随机密码串，并使用服务器的公用密钥对其进行加密（参考非对称加 / 解密），并将加密后的信息发送给服务器；
>+ 4.客户端与服务器端根据 pre_master_secret 以及客户端与服务器的随机数值独立计算出加密和 MAC密钥（参考 DH密钥交换算法；
>+ 5.客户端将所有握手消息的 MAC 值发送给服务器；
>+ 6.服务器将所有握手消息的 MAC 值发送给客户端。

**优点**:
>+ 1.使用 HTTPS 协议可认证用户和服务器，确保数据发送到正确的客户机和服务器；
>+ 2.HTTPS 协议是由 SSL+HTTP 构建的可进行加密传输、身份认证的网络协议，要比 HTTP安全，可防止数据在传输过程中被窃取、改变，确保数据的完整性。
>+ 3.HTTPS 是现行架构下最安全的解决方案，虽然不是绝对安全，但它大幅增加了中间人攻击的成本。

**缺点**:
>+ 1.相同网络环境下，HTTPS 协议会使页面的加载时间延长近 50%，增加 10% 到 20% 的耗电。此外，HTTPS 协议还会影响缓存，增加数据开销和功耗。
>+ 2.HTTPS 协议的安全是有范围的，在黑客攻击、拒绝服务攻击和服务器劫持等方面几乎起不到什么作用。
>+ 3.最关键的是，SSL 证书的信用链体系并不安全。特别是在某些国家可以控制 CA 根证书的情况下，中间人攻击一样可行。
>+ 4.成本增加。部署 HTTPS 后，因为 HTTPS 协议的工作要增加额外的计算资源消耗，例如 SSL 协议加密算法和 SSL 交互次数将占用一定的计算资源和服务器成本。在大规模用户访问应用的场景下，服务器需要频繁地做加密和解密操作，几乎每一个字节都需要做加解密，这就产生了服务器成本。随着云计算技术的发展，数据中心部署的服务器使用成本在规模增加后逐步下降，相对于用户访问的安全提升，其投入成本已经下降到可接受程度。

# 8.高频面试题

<font face="黑体" color=#D02090 size=5>1.UDP和TCP的特点与区别</font>

**用户数据报协议 UDP（User Datagram Protocol）**
是无连接的，尽最大可能交付，没有拥塞控制，面向报文（对于应用程序传下来的报文不合并也不拆分，只是添加 UDP 首部），支持一对一、一对多、多对一和多对多的交互通信。

**传输控制协议 TCP（Transmission Control Protocol）**
是面向连接的，提供可靠交付，有流量控制，拥塞控制，提供全双工通信，面向字节流（把应用层传下来的报文看成字节流，把字节流组织成大小不等的数据块），每一条 TCP 连接只能是点对点的（一对一）。

<font face="黑体" color=#D02090 size=5>2.为什么是三次握手</font>

客户端和服务端通信前要进行连接，“3次握手” 的作用就是双方都能明确自己和对方的收、发能力是正常的。

**第一次握手**：客户端发送网络包，服务端收到了。这样服务端就能得出结论：客户端的发送能力、服务端的接收能力是正常的。

**第二次握手**：服务端发包，客户端收到了。这样客户端就能得出结论：服务端的接收、发送能力，客户端的接收、发送能力是正常的。从客户端的视角来看，我接到了服务端发送过来的响应数据包，说明服务端接收到了我在第一次握手时发送的网络包，并且成功发送了响应数据包，这就说明，服务端的接收、发送能力正常。而另一方面，我收到了服务端的响应数据包，说明我第一次发送的网络包成功到达服务端，这样，我自己的发送和接收能力也是正常的。

**第三次握手**：客户端发包，服务端收到了。这样服务端就能得出结论：客户端的接收、发送能力，服务端的发送、接收能力是正常的。第一、二次握手后，服务端并不知道客户端的接收能力以及自己的发送能力是否正常。而在第三次握手时，服务端收到了客户端对第二次握手作的回应。从服务端的角度，我在第二次握手时的响应数据发送出去了，客户端接收到了。所以，我的发送能力是正常的。而客户端的接收能力也是正常的。

经历了上面的三次握手过程，客户端和服务端都确认了自己的接收、发送能力是正常的。之后就可以正常通信了。

每次都是接收到数据包的一方可以得到一些结论，发送的一方其实没有任何头绪。我虽然有发包的动作，但是我怎么知道我有没有发出去，而对方有没有接收到呢？而从上面的过程可以看到，最少是需要三次握手过程的。两次达不到让双方都得出自己、对方的接收、发送能力都正常的结论。

<font face="黑体" color=#D02090 size=5>3.为什么是四次挥手</font>

1、TCP连接是双向传输的对等的模式，就是说双方都可以同时向对方发送或接收数据。当有一方要关闭连接时，会发送指令告知对方，我要关闭连接了。

2、这时对方会回一个 ACK，此时一个方向的连接关闭。但是另一个方向仍然可以继续传输数据，也就是说，服务端收到客户端的 FIN 标志，知道客户端想要断开这次连接了，但是，我服务端，我还想发数据呢？我等到发送完了所有的数据后，会发送一个 FIN 段来关闭此方向上的连接。接收方发送 ACK确认关闭连接。

（注意，接收到FIN报文的一方只能回复一个 ACK, 它是无法马上返回对方一个 FIN 报文段的，因为结束数据传输的 “指令” 是上层应用层给出的，我只是一个 “搬运工”，我无法了解 “上层的意志”。）

3、客户端发送了 FIN 连接释放报文之后，服务器收到了这个报文，就进入了 CLOSE-WAIT 状态。这个状态是为了让服务器端发送还未传送完毕的数据，传送完毕之后，服务器会发送 FIN 连接释放报文。

4、因为服务端在 LISTEN 状态下，收到建立连接请求的 SYN 报文后，把 ACK 和 SYN 放在一个报文里发送给客户端。而关闭连接时，当收到对方的 FIN 报文时，仅仅表示对方不再发送数据了但是还能接收数据，己方是否现在关闭发送数据通道，需要上层应用来决定，因此，己方 ACK 和 FIN 一般都会分开发。

<font face="黑体" color=#D02090 size=5>4.为什么需要TIME_WAIT状态</font>

1）**可靠地实现TCP全双工连接的终止**。
TCP协议在关闭连接的四次握手过程中，最终的ACK是由主动关闭连接的一端（后面统称A端）发出的，如果这个ACK丢失，对方（后面统称B端）将重发出最终的FIN，因此A端必须维护状态信息（TIME_WAIT）允许它重发最终的ACK。如果A端不维持TIME_WAIT状态，而是处于CLOSED 状态，那么A端将响应RST分节，B端收到后将此分节解释成一个错误。因而，要实现TCP全双工连接的正常终止，必须处理终止过程中四个分节任何一个分节的丢失情况，主动关闭连接的A端必须维持TIME_WAIT状态 。

2）**允许老的重复分节在网络中消逝**。
TCP分节可能由于路由器异常而“迷途”，在迷途期间，TCP发送端可能因确认超时而重发这个分节，迷途的分节在路由器修复后也会被送到最终目的地，这个迟到的迷途分节到达时可能会引起问题。在关闭“前一个连接”之后，马上又重新建立起一个相同的IP和端口之间的“新连接”，“前一个连接”的迷途重复分组在“前一个连接”终止后到达，而被“新连接”收到了。为了避免这个情况，TCP协议不允许处于TIME_WAIT状态的连接启动一个新的可用连接，因为TIME_WAIT状态持续2MSL，就可以保证当成功建立一个新TCP连接的时候，来自旧连接重复分组已经在网络中消逝。

**为什么要等待 2 MSL?**
>+ 1 个 MSL 确保四次挥手中主动关闭方最后的 ACK 报文最终能达到对端
>+ 1 个 MSL 确保对端没有收到 ACK 重传的 FIN 报文可以到达

(**MSL**就是maximum segment lifetime(最大分节生命期），这是一个IP数据包能在互联网上生存的最长时间，超过这个时间IP数据包将在网络中消失。)

<font face="黑体" color=#D02090 size=5>5.TCP粘包、拆包及解决办法</font>

**为什么会发生 TCP 粘包、拆包？**
>+ 要发送的数据大于 TCP 发送缓冲区剩余空间大小，将会发生拆包。
>+ 待发送数据大于 MSS（最大报文长度），TCP 在传输前将进行拆包。
>+ 要发送的数据小于 TCP 发送缓冲区的大小，TCP 将多次写入缓冲区的数据一次发送出去，将会发生粘包。
>+ 接收数据端的应用层没有及时读取接收缓冲区中的数据，将发生粘包。

**粘包、拆包解决办法**
由于 TCP 本身是面向字节流的，无法理解上层的业务数据，所以在底层是无法保证数据包不被拆分和重组的，这个问题只能通过上层的应用协议栈设计来解决，根据业界的主流协议的解决方案，归纳如下：
>+ **消息定长**：发送端将每个数据包封装为固定长度（不够的可以通过补 0 填充），这样接收端每次接收缓冲区中读取固定长度的数据就自然而然的把每个数据包拆分开来。
>+ **设置消息边界**：服务端从网络流中按消息边界分离出消息内容。在包尾增加回车换行符进行分割，例如 FTP 协议。
>+ **将消息分为消息头和消息体**：消息头中包含表示消息总长度（或者消息体长度）的字段。
>+ 更复杂的应用层协议比如 Netty 中实现的一些协议都对粘包、拆包做了很好的处理。

**为什么常说 TCP 有粘包和拆包的问题而不说 UDP ？**
由前两节可知，UDP 是基于报文发送的，UDP首部采用了 16bit 来指示 UDP 数据报文的长度，因此在应用层能很好的将不同的数据报文区分开，从而避免粘包和拆包的问题。

而 TCP 是基于字节流的，虽然应用层和 TCP 传输层之间的数据交互是大小不等的数据块，但是 TCP 并没有把这些数据块区分边界，仅仅是一连串没有结构的字节流；另外从 TCP 的帧结构也可以看出，在 TCP 的首部没有表示数据长度的字段，基于上面两点，在使用 TCP 传输数据时，才有粘包或者拆包现象发生的可能。

<font face="黑体" color=#D02090 size=5>6.半连接队列和 SYN Flood 攻击的关系</font>

三次握手前，服务端的状态从CLOSED变为LISTEN, 同时在内部创建了两个队列：半连接队列和全连接队列，即SYN队列和ACCEPT队列。

**半连接队列**: 当客户端发送SYN到服务端，服务端收到以后回复ACK和SYN，状态由LISTEN变为SYN_RCVD，此时这个连接就被推入了SYN队列，也就是半连接队列。

**全连接队列**: 当客户端返回ACK, 服务端接收后，三次握手完成。这个时候连接等待被具体的应用取走，在被取走之前，它会被推入另外一个 TCP 维护的队列，也就是全连接队列(Accept Queue)。

**SYN Flood 攻击原理**:SYN Flood 属于典型的 DoS/DDoS 攻击。其攻击的原理很简单，就是用客户端在短时间内伪造大量不存在的 IP 地址，并向服务端疯狂发送SYN。对于服务端而言，会产生两个危险的后果:
>+ 处理大量的SYN包并返回对应ACK, 势必有大量连接处于SYN_RCVD状态，从而占满整个半连接队列，无法处理正常的请求。
>+ 由于是不存在的 IP，服务端长时间收不到客户端的ACK，会导致服务端不断重发数据，直到耗尽服务端的资源。

**如何应对 SYN Flood 攻击？**:
>+ 增加 SYN 连接，也就是增加半连接队列的容量。
>+ 减少 SYN + ACK 重试次数，避免大量的超时重发。
>+ 利用 SYN Cookie 技术，在服务端接收到SYN后不立即分配连接资源，而是根据这个SYN计算出一个Cookie，连同第二次握手回复给客户端，在客户端回复ACK的时候带上这个Cookie值，服务端验证 Cookie 合法之后才分配连接资源。

<font face="黑体" color=#D02090 size=5>7.TCP快速打开的原理(TFO)</font>

**TFO工作原理**:
>+ 客户端发送SYN包，包尾加一个 FOC 请求，只有 4个字节。
>+ 服务端受到 FOC 请求，验证后根据来源 ip 地址生成 cookie(8个字节)，将这个 COOKIE 加载到 SYN+ACK 包的末尾发送回去。
>+ 客户端缓存住获取到的 Cookie 可以给下一次使用。
>+ 下一次请求开始，客户端发送 SYN 包，这时候后面带上缓存的 COOKIE，然后就是正式发送的数据。
>+ 服务器端验证 COOKIE 正确，将数据交给上层应用处理得到相应结果，然后在发送 SYN+ACK 时，不再等待客户端的 ACK 确认，即开始发送相应数据。

<div align=center><img src="https://pic2.zhimg.com/80/v2-4b00ec1392a6b2edf40c36e7456b69f5_720w.jpg" width="80%" height="60%"></div>

**TFO 的优势**：TFO 的优势并不在与首轮三次握手，而在于后面的握手，在拿到客户端的 Cookie 并验证通过以后，可以直接返回 HTTP 响应，充分利用了1 个RTT(Round-Trip Time，往返时延)的时间提前进行数据传输，积累起来还是一个比较大的优势。

(RTT(Round-Trip Time)，往返时延。在计算机网络中它是一个重要的性能指标，表示从发送端发送数据开始，到发送端收到来自接收端的确认（接收端收到数据后便立即发送确认），总共经历的时延。

往返延时(RTT)由三个部分决定：即链路的传播时间、末端系统的处理时间以及路由器的缓存中的排队和处理时间。其中，前面两个部分的值作为一个TCP连接相对固定，路由器的缓存中的排队和处理时间会随着整个网络拥塞程度的变化而变化。所以RTT的变化在一定程度上反映了网络拥塞程度的变化。)

<font face="黑体" color=#D02090 size=5>8.如果已经建立了连接，但是客户端突然出现故障了怎么办？</font>

TCP设有一个保活计时器，客户端如果出现故障，服务器不能一直等下去，白白浪费资源。服务器每收到一次客户端的请求后都会重新复位这个计时器，时间通常是设置为2小时，若两小时还没有收到客户端的任何数据，服务器就会发送一个探测报文段，以后每隔75秒钟发送一次。若一连发送10个探测报文仍然没反应，服务器就认为客户端出了故障，接着就关闭连接。

<font face="黑体" color=#D02090 size=5>9.Socket编程流程</font>

**服务器端**：
>+ 服务端初始化 Socket，得到文件描述符
>+ 服务端调用 Bind，将绑定在 IP 地址和端口
>+ 服务端调用 Listen，进行监听
>+ 服务端调用 Accept，建立客户端连接
>+ 通过Send向客户端发送消息
>+ 通过Receive接收客户端消息

**客户端**：
>+ 客户端初始化 Socket，得到文件描述符
>+ 客户端调用 Connect，连接服务器
>+ 连接成功调用 Send 向客户端发送消息
>+ 通过 Receive 接收客户端消息

<font face="黑体" color=#D02090 size=5>10.搜索baidu，会用到计算机网络中的什么层？</font>

**浏览器中输入URL**： 浏览器要将URL解析为IP地址，解析域名就要用到DNS协议，首先主机会查询DNS的缓存，如果没有就给本地DNS发送查询请求。DNS查询分为两种方式，一种是递归查询，一种是迭代查询。如果是迭代查询，本地的DNS服务器，向根域名服务器发送查询请求，根域名服务器告知该域名的一级域名服务器，然后本地服务器给该一级域名服务器发送查询请求，然后依次类推直到查询到该域名的IP地址。DNS服务器是基于UDP的，因此会用到UDP协议。

得到IP地址后，浏览器就要与服务器建立一个http连接。因此要用到http协议，http协议报文格式上面已经提到。http生成一个get请求报文，将该报文传给TCP层处理，所以还会用到TCP协议。如果采用https还会使用https协议先对http数据进行加密。TCP层如果有需要先将HTTP数据包分片，分片依据路径MTU和MSS。TCP的数据包然后会发送给IP层，用到IP协议。IP层通过路由选路，一跳一跳发送到目的地址。当然在一个网段内的寻址是通过以太网协议实现(也可以是其他物理层协议，比如PPP，SLIP)，以太网协议需要直到目的IP地址的物理地址，又需要ARP协议。

**作用**：
>+ **应用层是体系结构中的最高层**。 应用层确定进程之间通信的性质以满足用户的需要。这里的进程就是指正在运行的程序。应用层不仅要提供应用进程所需要的信息交换和远地操作，而且还要作为互相作用的应用进程的用户代理，来完成一些为进行语义上有意义的信息交换所必须的功能。应用层直接为用户的应用进程提供服务。
>+ **传输层的任务就是负责主机中两个进程之间的通信**。 因特网的传输层可使用两种不同协议：即面向连接的传输控制协议TCP，和无连接的用户数据报协议UDP。面向连接的服务能够提供可靠的交付，但无连接服务则不保证提供可靠的交付，它只是“尽最大努力交付”。这两种服务方式都很有用，备有其优缺点。在分组交换网内的各个交换结点机都没有传输层。
>+ **网络层负责为分组交换网上的不同主机提供通信**。 在发送数据时，网络层将运输层产生的报文段或用户数据报封装成分组或包进行传送。在TCP/IP体系中，分组也叫作IP数据报，或简称为数据报。网络层的另一个任务就是要选择合适的路由，使源主机运输层所传下来的分组能够交付到目的主机。
>+ **数据链路层的任务是将在网络层交下来的IP数据报组装成帧，在两个相邻结点间的链路上传送以帧为单位的数据**。每一帧包括数据和必要的控制信息（如同步信息、地址信息、差错控制、以及流量控制信息等）。控制信息使接收端能够知道—个帧从哪个比特开始和到哪个比特结束。控制信息还使接收端能够检测到所收到的帧中有无差错。
>+ **物理层的任务就是透明地传送比特流**。 在物理层上所传数据的单位是比特。传递信息所利用的一些物理媒体，如双绞线、同轴电缆、光缆等，并不在物理层之内而是在物理层的下面。因此也有人把物理媒体当做第0层。

<font face="黑体" color=#D02090 size=5>11.DNS解析过程</font>

>+ 1.浏览器先检查自身缓存中有没有被解析过的这个域名对应的ip地址，如果有，解析结束。同时域名被缓存的时间也可通过TTL属性来设置。
>+ 2.如果浏览器缓存中没有（专业点叫还没命中），浏览器会检查操作系统缓存中有没有对应的已解析过的结果。而操作系统也有一个域名解析的过程。在windows中可通过c盘里一个叫hosts的文件来设置，如果你在这里指定了一个域名对应的ip地址，那浏览器会首先使用这个ip地址。但是这种操作系统级别的域名解析规程也被很多黑客利用，通过修改你的hosts文件里的内容把特定的域名解析到他指定的ip地址上，造成所谓的域名劫持。所以在windows7中将hosts文件设置成了readonly，防止被恶意篡改。
>+ 3.如果至此还没有命中域名，才会真正的请求本地域名服务器（LDNS）来解析这个域名，这台服务器一般在你的城市的某个角落，距离你不会很远，并且这台服务器的性能都很好，一般都会缓存域名解析结果，大约80%的域名解析到这里就完成了。
>+ 4.如果LDNS仍然没有命中，就直接跳到Root Server 域名服务器请求解析
>+ 5.根域名服务器返回给LDNS一个所查询域的主域名服务器（gTLD Server，国际顶尖域名服务器，如.com .cn .org等）地址
>+ 6.此时LDNS再发送请求给上一步返回的gTLD
>+ 7.接受请求的gTLD查找并返回这个域名对应的Name Server的地址，这个Name Server就是网站注册的域名服务器
>+ 8.Name Server根据映射关系表找到目标ip，返回给LDNS
>+ 9.LDNS缓存这个域名和对应的ip
>+ 10.LDNS把解析的结果返回给用户，用户根据TTL值缓存到本地系统缓存中，域名解析过程至此结束

<font face="黑体" color=#D02090 size=5>12.负载均衡 反向代理模式的优点、缺点</font>

**反向代理（Reverse Proxy）**方式是指以代理服务器来接受internet上的连接请求，然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给internet上请求连接的客户端，此时代理服务器对外就表现为一个服务器。
**反向代理负载均衡**技术是把将来自internet上的连接请求以反向代理的方式动态地转发给内部网络上的多台服务器进行处理，从而达到负载均衡的目的。

**优点**：反向代理负载均衡能以软件方式来实现，如apache mod_proxy、netscape proxy等，也可以在高速缓存器、负载均衡器等硬件设备上实现。反向代理负载均衡可以将优化的负载均衡策略和代理服务器的高速缓存技术结合在一起，提升静态网页的访问速度，提供有益的性能；由于网络外部用户不能直接访问真实的服务器，具备额外的安全性（同理，NAT负载均衡技术也有此优点）。

**缺点**：反向代理是处于OSI参考模型第七层应用的，所以就必须为每一种应用服务专门开发一个反向代理服务器，这样就限制了反向代理负载均衡技术的应用范围，现在一般都用于对web服务器的负载均衡。针对每一次代理，代理服务器就必须打开两个连接，一个对外，一个对内，因此在并发连接请求数量非常大的时候，代理服务器的负载也就非常大了，在最后代理服务器本身会成为服务的瓶颈。一般来讲，可以用它来对连接数量不是特别大，但每次连接都需要消耗大量处理资源的站点进行负载均衡，如search等。

<font face="黑体" color=#D02090 size=5>13.Session</font>

**Session**：在web开发中，服务器可以为每个用户创建一个会话对象(session对象)，默认情况下一个浏览器独占一个session对象，因此在需要保存用户数据时，服务器程序可以把用户数据写到用户浏览器独占的session中，当用户使用浏览器访问其他程序时，其他程序可以从用户的session中取出该用户的数据，为用户服务，其实现原理是服务器创建session出来后，会把session的id号，以cookie的形式回写给客户机，这样只要客户机的浏览器不关，再去访问服务器时，都会带着session的id号去，服务器发现客户机浏览器带session id过来了，就会使用内存中与之对应的session服务。

**Session和cookie的区别**：
>+ 1、cookie是把用户的数据写给用户浏览器
>+ 2、session是把用户的数据写到用户独占的session中
>+ 3、session对象由服务器创建，开发人员可以调用request对象的getsession方法得到session对象

<font face="黑体" color=#D02090 size=5>14.Ping的整个过程</font>

同一个局域网中：
>+ 1.Pc1在应用层发起个目标IP位IP2的Ping请求。
>+ 2.传输层接到上层请求的数据，将数据分段并加上UDP报头。下传到Internet层。
>+ 3.网际层接收来处上层的数据后，根据ICMP协议进行封装，添加PC1的IP为源IP为和PC2IP为目标IP后封装成数据包。下传到网络接口层。
>+ 4.网络接口层接收数据包后，进行封装，源MAC地址为PC1的MAC地址，目标MAC地址则查询自己的ARP缓存表获取。如果PC1 arp缓存表中没有目标IP对应的MAC地址，则PC1发出一个ARP广播报文。ARP报文中源MAC地址为Pc1mac地址，源IP地址为pc1 IP，所要请求的是PC2的IP对应的mac地址。
>+ 5.PC2收到ARP广播后，进行解封装，发现所请求的MAC地址是自己的。则PC2将PC1的mac地址写入arp缓存表中。然后向PC1发送一个 ARP应答单播。该单播消息包括目标IP为PC1ip，目标Mac为pc1mac地址，源IP为PC2的IP，源Mac为pc2的Mac。
>+ 6.Pc1接收到PC2的arp应答报文后，将Pc2的MAC地址存入arp缓存中，并将Pc2的Mac地址作为目标地址封装到数据帧中。发给下层进行网络传输。
>+ 7.PC2接收这个帧后，在网络接口层查看目标mac地址是否指向自己。是，PC2则将帧头去掉，向上层传输。
>+ 8.Pc2网际层接收到这个信息包，查看包头，发现目标IP和自己匹配，则解封装，将数据向上层传输。
>+ 9.传输层接收来自下层的Ping请求的UDP报文，则去掉UDP报头，向应用层传送。
>+ 10.应用层收到ping请求后，发送一个PIng回应报文给PC1